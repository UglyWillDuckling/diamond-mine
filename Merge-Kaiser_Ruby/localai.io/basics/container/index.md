-   [![](https://github.com/go-skynet/LocalAI/assets/2420543/0966aa2a-166e-4f99-a3e5-6c915fc997dd){style="width:calc(65%);height:calc(65%)"}](../../index.html){aria-label="HomePage"
    alt="HomePage"}

    LocalAI

-   [![](https://img.shields.io/github/release/go-skynet/LocalAI?&label=Latest&style=for-the-badge)](https://github.com/go-skynet/LocalAI/releases)

-   [![](https://img.shields.io/badge/dockerhub-images-important.svg?logo=Docker)](https://hub.docker.com/r/localai/localai){target="_blank"}
    [![](https://img.shields.io/badge/quay.io-images-important.svg?)](https://quay.io/repository/go-skynet/local-ai?tab=tags&tag=latest){target="_blank"}

-   [*info* Overview](../../index.html){.sidebar-root-link}
-   *rocket_launch* Getting started

    -   [Quickstart](../getting_started/index.html){.sidebar-nested-link}
    -   [Install and Run
        Models](https://localai.io/docs/getting-started/models/){.sidebar-nested-link}
    -   [Try it out](../try/index.html){.sidebar-nested-link}
    -   [Customizing the
        Model](https://localai.io/docs/getting-started/customize-model/){.sidebar-nested-link}
    -   [Build LocalAI from
        source](../build/index.html){.sidebar-nested-link}
    -   [Run with container images](index.html){.sidebar-nested-link}
    -   [Run with
        Kubernetes](../kubernetes/index.html){.sidebar-nested-link}
-   [*newspaper* News](../news/index.html){.sidebar-root-link}
-   *feature_search* Features

    -   [‚ö° GPU
        acceleration](../../features/gpu-acceleration/index.html){.sidebar-nested-link}
    -   [üìñ Text generation
        (GPT)](../../features/text-generation/index.html){.sidebar-nested-link}
    -   [üìà
        Reranker](../../features/reranker/index.html){.sidebar-nested-link}
    -   [üó£ Text to audio
        (TTS)](../../features/text-to-audio/index.html){.sidebar-nested-link}
    -   [üé® Image
        generation](../../features/image-generation/index.html){.sidebar-nested-link}
    -   [üß†
        Embeddings](../../features/embeddings/index.html){.sidebar-nested-link}
    -   [ü•Ω GPT
        Vision](../../features/gpt-vision/index.html){.sidebar-nested-link}
    -   [‚úçÔ∏è Constrained
        Grammars](../../features/constrained_grammars/index.html){.sidebar-nested-link}
    -   [üÜïüñß Distributed
        Inference](../../features/distribute/index.html){.sidebar-nested-link}
    -   [üîà Audio to
        text](../../features/audio-to-text/index.html){.sidebar-nested-link}
    -   [üî• OpenAI functions and
        tools](../../features/openai-functions/index.html){.sidebar-nested-link}
    -   [üíæ Stores](../../stores/index.html){.sidebar-nested-link}
    -   [üñºÔ∏è Model
        gallery](../../models/index.html){.sidebar-nested-link}
-   [*sync*
    Integrations](https://localai.io/docs/integrations/){.sidebar-root-link}
-   *settings* Advanced

    -   [Advanced
        usage](../../advanced/index.html){.sidebar-nested-link}
    -   [Fine-tuning LLMs for text
        generation](https://localai.io/docs/advanced/fine-tuning/){.sidebar-nested-link}
    -   [Installer
        options](https://localai.io/docs/advanced/installer/){.sidebar-nested-link}
-   *menu_book* References

    -   [Model compatibility
        table](../../model-compatibility/index.html){.sidebar-nested-link}
    -   [Architecture](https://localai.io/docs/reference/architecture/){.sidebar-nested-link}
    -   [LocalAI
        binaries](https://localai.io/docs/reference/binaries/){.sidebar-nested-link}
    -   [Running on Nvidia
        ARM64](https://localai.io/docs/reference/nvidia-l4t/){.sidebar-nested-link}
-   [*quiz* FAQ](../../faq/index.html){.sidebar-root-link}

[](../../index.html){.logo-icon .me-3 aria-label="HomePage"
alt="HomePage"}

![](data:image/svg+xml;base64,PHN2ZyBpZD0iTGF5ZXJfMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2aWV3Ym94PSIwIDAgMjUwIDI1MCI+PHBhdGggZD0ibTE0MyAzOS41Yy0xOCAwLTE4IDE4LTE4IDE4czAtMTgtMTgtMThIMjJjLTIuNzYuMC01IDIuMjQtNSA1djE0M2MwIDIuNzYgMi4yNCA1IDUgNWg3NmM3LjIuMCA4LjY0IDExLjUyIDguOTMgMTYuMTMuMDcgMS4wNS45NSAxLjg3IDIgMS44N2gzMi4xNGMxLjA2LjAgMS45NC0uODIgMi0xLjg3LjI5LTQuNjEgMS43My0xNi4xMyA4LjkzLTE2LjEzaDc2YzIuNzYuMCA1LTIuMjQgNS01VjQ0LjVjMC0yLjc2LTIuMjQtNS01LTVoLTg1ek0yMDYgMTYzYzAgMS4zOC0xLjEyIDIuNS0yLjUgMi41SDE0M2MtMTggMC0xOCAxOC0xOCAxOHMwLTE4LTE4LTE4SDQ2LjVjLTEuMzguMC0yLjUtMS4xMi0yLjUtMi41VjY5YzAtMS4zOCAxLjEyLTIuNSAyLjUtMi41SDk4YzcuMi4wIDguNjQgMTEuNTIgOC45MyAxNi4xMy4wNyAxLjA1Ljk1IDEuODcgMiAxLjg3aDMyLjE0YzEuMDYuMCAxLjk0LS44MiAyLTEuODcuMjktNC42MSAxLjczLTE2LjEzIDguOTMtMTYuMTNoNTEuNWMxLjM4LjAgMi41IDEuMTIgMi41IDIuNXY5NHoiIHN0eWxlPSJmaWxsOiMwNmYiIC8+PC9zdmc+){#Layer_1}

![](data:image/svg+xml;base64,PHN2ZyBpZD0iTGF5ZXJfMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2aWV3Ym94PSIwIDAgMjUwIDI1MCI+PHBhdGggZD0ibTE0MyAzOS41Yy0xOCAwLTE4IDE4LTE4IDE4czAtMTgtMTgtMThIMjJjLTIuNzYuMC01IDIuMjQtNSA1djE0M2MwIDIuNzYgMi4yNCA1IDUgNWg3NmM3LjIuMCA4LjY0IDExLjUyIDguOTMgMTYuMTMuMDcgMS4wNS45NSAxLjg3IDIgMS44N2gzMi4xNGMxLjA2LjAgMS45NC0uODIgMi0xLjg3LjI5LTQuNjEgMS43My0xNi4xMyA4LjkzLTE2LjEzaDc2YzIuNzYuMCA1LTIuMjQgNS01VjQ0LjVjMC0yLjc2LTIuMjQtNS01LTVoLTg1ek0yMDYgMTYzYzAgMS4zOC0xLjEyIDIuNS0yLjUgMi41SDE0M2MtMTggMC0xOCAxOC0xOCAxOHMwLTE4LTE4LTE4SDQ2LjVjLTEuMzguMC0yLjUtMS4xMi0yLjUtMi41VjY5YzAtMS4zOCAxLjEyLTIuNSAyLjUtMi41SDk4YzcuMi4wIDguNjQgMTEuNTIgOC45MyAxNi4xMy4wNyAxLjA1Ljk1IDEuODcgMiAxLjg3aDMyLjE0YzEuMDYuMCAxLjk0LS44MiAyLTEuODcuMjktNC42MSAxLjczLTE2LjEzIDguOTMtMTYuMTNoNTEuNWMxLjM4LjAgMi41IDEuMTIgMi41IDIuNXY5NHoiIHN0eWxlPSJmaWxsOiMwNmYiIC8+PC9zdmc+){#Layer_1}

[menu]{.material-icons .size-20 .menu-icon .align-middle}

[search]{.material-icons .size-20 .menu-icon .align-middle}
[Search]{.flexsearch-button-placeholder .ms-1 .me-2 .d-none .d-sm-block}

[[![](data:image/svg+xml;base64,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)]{.kbd
.flexsearch-button-cmd-key}[![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUiIGhlaWdodD0iMTUiPjxwYXRoIGQ9Ik01LjkyNiAxMi4yNzlINC40MUw5LjA3MyAyLjcyMUgxMC41OXoiIGZpbGw9ImN1cnJlbnRjb2xvciIgLz48L3N2Zz4=)]{.kbd
.flexsearch-button-key}]{.flexsearch-button-keys}

##### Star us on GitHub !¬†

[Star](https://github.com/mudler/LocalAI){.github-button
color-scheme="no-preference: light; light: light; dark: dark;"
icon="octicon-star" data-size="large" show-count="true"
aria-label="Star mudler/LocalAI on GitHub"}

-   [](https://github.com/mudler/LocalAI){alt="github"
    rel="noopener noreferrer" target="_blank"}

    ![](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld2JveD0iMCAwIDI0IDI0IiBmaWxsPSJub25lIiBzdHJva2U9ImN1cnJlbnRjb2xvciIgc3Ryb2tlLXdpZHRoPSIyIiBzdHJva2UtbGluZWNhcD0icm91bmQiIHN0cm9rZS1saW5lam9pbj0icm91bmQiPjx0aXRsZT5HaXRIdWI8L3RpdGxlPjxwYXRoIGQ9Ik05IDE5Yy01IDEuNS01LTIuNS03LTNtMTQgNnYtMy44N2EzLjM3IDMuMzcuMCAwMC0uOTQtMi42MWMzLjE0LS4zNSA2LjQ0LTEuNTQgNi40NC03QTUuNDQgNS40NC4wIDAwMjAgNC43NyA1LjA3IDUuMDcuMCAwMDE5LjkxIDFTMTguNzMuNjUgMTYgMi40OGExMy4zOCAxMy4zOC4wIDAwLTcgMEM2LjI3LjY1IDUuMDkgMSA1LjA5IDFBNS4wNyA1LjA3LjAgMDA1IDQuNzcgNS40NCA1LjQ0LjAgMDAzLjUgOC41NWMwIDUuNDIgMy4zIDYuNjEgNi40NCA3QTMuMzcgMy4zNy4wIDAwOSAxOC4xM1YyMiIgLz48L3N2Zz4=)
-   [](https://twitter.com/LocalAI_API){alt="twitter"
    rel="noopener noreferrer" target="_blank"}

    ![](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld2JveD0iMCAwIDI0IDI0Ij48dGl0bGU+VHdpdHRlciAvIFg8L3RpdGxlPjxwYXRoIGQ9Ik0uMDg4Ljc2OGw5LjI2NiAxMi4zOUwuMDI5IDIzLjIzMWgyLjFsOC4xNjMtOC44MTkgNi42IDguODE5aDcuMTQyTDE0LjI0MiAxMC4xNDUgMjIuOTIxLjc2OGgtMi4xTDEzLjMgOC44OTEgNy4yMjkuNzY4ek0zLjE3NCAyLjMxNEg2LjQ1NUwyMC45NDIgMjEuNjg1aC0zLjI4eiIgZmlsbD0iY3VycmVudGNvbG9yIiAvPjwvc3ZnPg==)
-   [](../../index.xml){alt="rss" rel="noopener noreferrer"
    target="_blank"}

    ![](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld2JveD0iMCAwIDI0IDI0IiBmaWxsPSJub25lIiBzdHJva2U9ImN1cnJlbnRjb2xvciIgc3Ryb2tlLXdpZHRoPSIyIiBzdHJva2UtbGluZWNhcD0icm91bmQiIHN0cm9rZS1saW5lam9pbj0icm91bmQiPjx0aXRsZT5SU1M8L3RpdGxlPjxwYXRoIGQ9Ik00IDExYTkgOSAwIDAxOSA5IiAvPjxwYXRoIGQ9Ik00IDRhMTYgMTYgMCAwMTE2IDE2IiAvPjxjaXJjbGUgY3g9IjUiIGN5PSIxOSIgcj0iMSI+PC9jaXJjbGU+PC9zdmc+)

[![](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMzAiIHdpZHRoPSIzMCIgdmlld2JveD0iMCAwIDQ4IDQ4IiBmaWxsPSJjdXJyZW50Y29sb3IiPjx0aXRsZT5FbmFibGUgZGFyayBtb2RlPC90aXRsZT48cGF0aCBkPSJNMjQgNDJxLTcuNS4wLTEyLjc1LTUuMjVUNiAyNHQ1LjI1LTEyLjc1VDI0IDZxLjQuMC44NS4wMjUuNDUuMDI1IDEuMTUuMDc1LTEuOCAxLjYtMi44IDMuOTV0LTEgNC45NXEwIDQuNSAzLjE1IDcuNjVRMjguNSAyNS44IDMzIDI1LjhxMi42LjAgNC45NS0uOTI1VDQxLjkgMjIuM3EuMDUuNi4wNzUuOTc1UTQyIDIzLjY1IDQyIDI0cTAgNy41LTUuMjUgMTIuNzVUMjQgNDJ6bTAtM3E1LjQ1LjAgOS41LTMuMzc1dDUuMDUtNy45MjVxLTEuMjUuNTUtMi42NzUuODI1UTM0LjQ1IDI4LjggMzMgMjguOHEtNS43NS4wLTkuNzc1LTQuMDI1VDE5LjIgMTVxMC0xLjIuMjUtMi41NzV0LjktMy4xMjVxLTQuOSAxLjM1LTguMTI1IDUuNDc1UTkgMTguOSA5IDI0cTAgNi4yNSA0LjM3NSAxMC42MjVUMjQgMzl6bS0uMi0xNC44NXoiIC8+PC9zdmc+)]{.toggle-dark}[![](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMzAiIHdpZHRoPSIzMCIgdmlld2JveD0iMCAwIDQ4IDQ4IiBmaWxsPSJjdXJyZW50Y29sb3IiPjx0aXRsZT5FbmFibGUgbGlnaHQgbW9kZTwvdGl0bGU+PHBhdGggZD0iTTI0IDMxcTIuOS4wIDQuOTUtMi4wNVQzMSAyNHQtMi4wNS00Ljk1VDI0IDE3dC00Ljk1IDIuMDVUMTcgMjR0Mi4wNSA0Ljk1VDI0IDMxem0wIDNxLTQuMTUuMC03LjA3NS0yLjkyNVQxNCAyNHQyLjkyNS03LjA3NVQyNCAxNHQ3LjA3NSAyLjkyNVQzNCAyNHQtMi45MjUgNy4wNzVUMjQgMzR6TTMuNSAyNS41cS0uNjUuMC0xLjA3NS0uNDI1UTIgMjQuNjUgMiAyNHQuNDI1LTEuMDc1UTIuODUgMjIuNSAzLjUgMjIuNWg1cS42NS4wIDEuMDc1LjQyNVExMCAyMy4zNSAxMCAyNHQtLjQyNSAxLjA3NVQ4LjUgMjUuNXptMzYgMHEtLjY1LjAtMS4wNzUtLjQyNVEzOCAyNC42NSAzOCAyNHQuNDI1LTEuMDc1VDM5LjUgMjIuNWg1cS42NS4wIDEuMDc1LjQyNVE0NiAyMy4zNSA0NiAyNHQtLjQyNSAxLjA3NS0xLjA3NS40MjV6TTI0IDEwcS0uNjUuMC0xLjA3NS0uNDI1UTIyLjUgOS4xNSAyMi41IDguNXYtNXEwLS42NS40MjUtMS4wNzVRMjMuMzUgMiAyNCAydDEuMDc1LjQyNVQyNS41IDMuNXY1cTAgLjY1LS40MjUgMS4wNzVRMjQuNjUgMTAgMjQgMTB6bTAgMzZxLS42NS4wLTEuMDc1LS40MjVUMjIuNSA0NC41di01cTAtLjY1LjQyNS0xLjA3NVEyMy4zNSAzOCAyNCAzOHQxLjA3NS40MjUuNDI1IDEuMDc1djVxMCAuNjUtLjQyNSAxLjA3NVEyNC42NSA0NiAyNCA0NnpNMTIgMTQuMWwtMi44NS0yLjhxLS40NS0uNDUtLjQyNS0xLjA3NS4wMjUtLjYyNS40MjUtMS4wNzUuNDUtLjQ1IDEuMDc1LS40NXQxLjA3NS40NUwxNC4xIDEycS40LjQ1LjQgMS4wNS4wLjYtLjQgMS0uNC40NS0xLjAyNS40NVQxMiAxNC4xem0yNC43IDI0Ljc1TDMzLjkgMzZxLS40LS40NS0uNC0xLjA3NXQuNDUtMS4wMjVxLjQtLjQ1IDEtLjQ1dDEuMDUuNDVsMi44NSAyLjhxLjQ1LjQ1LjQyNSAxLjA3NS0uMDI1LjYyNS0uNDI1IDEuMDc1LS40NS40NS0xLjA3NS40NXQtMS4wNzUtLjQ1ek0zMy45IDE0LjFxLS40NS0uNDUtLjQ1LTEuMDUuMC0uNi40NS0xLjA1bDIuOC0yLjg1cS40NS0uNDUgMS4wNzUtLjQyNS42MjUuMDI1IDEuMDc1LjQyNS40NS40NS40NSAxLjA3NXQtLjQ1IDEuMDc1TDM2IDE0LjFxLS40LjQtMS4wMjUuNHQtMS4wNzUtLjR6TTkuMTUgMzguODVxLS40NS0uNDUtLjQ1LTEuMDc1dC40NS0xLjA3NUwxMiAzMy45cS40NS0uNDUgMS4wNS0uNDUuNi4wIDEuMDUuNDUuNDUuNDUuNDUgMS4wNS4wLjYtLjQ1IDEuMDVsLTIuOCAyLjg1cS0uNDUuNDUtMS4wNzUuNDI1LS42MjUtLjAyNS0xLjA3NS0uNDI1ek0yNCAyNHoiIC8+PC9zdmc+)]{.toggle-light}

[![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUiIGhlaWdodD0iMTUiIGFyaWEtbGFiZWw9IkFycm93IGRvd24iIHJvbGU9ImltZyI+PGcgZmlsbD0ibm9uZSIgc3Ryb2tlPSJjdXJyZW50Y29sb3IiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCIgc3Ryb2tlLWxpbmVqb2luPSJyb3VuZCIgc3Ryb2tlLXdpZHRoPSIxLjIiPjxwYXRoIGQ9Ik03LjUgMy41djhtMy0zLTMgMy0zLTMiIC8+PC9nPjwvc3ZnPg==)]{.kbd
.flexsearch-button-cmd-key}[![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUiIGhlaWdodD0iMTUiIGFyaWEtbGFiZWw9IkFycm93IHVwIiByb2xlPSJpbWciPjxnIGZpbGw9Im5vbmUiIHN0cm9rZT0iY3VycmVudGNvbG9yIiBzdHJva2UtbGluZWNhcD0icm91bmQiIHN0cm9rZS1saW5lam9pbj0icm91bmQiIHN0cm9rZS13aWR0aD0iMS4yIj48cGF0aCBkPSJNNy41IDExLjV2LThtMyAzLTMtMy0zIDMiIC8+PC9nPjwvc3ZnPg==)]{.kbd
.flexsearch-button-cmd-key}[to navigate]{.flexsearch-key-label}

[![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUiIGhlaWdodD0iMTUiIGFyaWEtbGFiZWw9IkVudGVyIGtleSIgcm9sZT0iaW1nIj48ZyBmaWxsPSJub25lIiBzdHJva2U9ImN1cnJlbnRjb2xvciIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIiBzdHJva2UtbGluZWpvaW49InJvdW5kIiBzdHJva2Utd2lkdGg9IjEuMiI+PHBhdGggZD0iTTEyIDMuNTMwODh2M2MwIDEtMSAyLTIgMkg0bTMgMy0zLTMgMy0zIiAvPjwvZz48L3N2Zz4=)]{.kbd
.flexsearch-button-cmd-key}[to select]{.flexsearch-key-label}

[![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUiIGhlaWdodD0iMTUiIGFyaWEtbGFiZWw9IkVzY2FwZSBrZXkiIHJvbGU9ImltZyI+PGcgZmlsbD0ibm9uZSIgc3Ryb2tlPSJjdXJyZW50Y29sb3IiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCIgc3Ryb2tlLWxpbmVqb2luPSJyb3VuZCIgc3Ryb2tlLXdpZHRoPSIxLjIiPjxwYXRoIGQ9Ik0xMy42MTY3IDguOTM2Yy0uMTA2NS4zNTgzLS42ODgzLjk2Mi0xLjQ4NzUuOTYyLS43OTkzLjAtMS42NTMtLjkxNjUtMS42NTMtMi4xMjU4di0uNTY3OGMwLTEuMjU0OC43ODk2LTIuMTAxNiAxLjY1My0yLjEwMTZzMS4zNjAxLjQ3NzggMS40ODc1IDEuMDcyNE05IDZjLS4xMzUyLS40NzM1LS43NTA2LS45MjE5LTEuNDYtLjg5NzItLjcwOTIuMDI0Ni0xLjM0NC41Ny0xLjM0NCAxLjIxNjZzLjQxOTguODgxMiAxLjM0NDUuOTgwNUM4LjQ2NSA3LjM5OTIgOC45NjggNy45MzM3IDkgOC41cy0uNDU0IDEuMzk4LTEuNDU5NSAxLjM5OEM2LjY1OTMgOS44OTggNiA5IDUuOTYzIDguNDg1MW0tMS40NzQ4LjUzNjhjLS4yNjM1LjU5NDEtLjgwOTkuODc2LTEuNTQ0My44NzZzLTEuNzA3My0uNjI0OC0xLjcwNzMtMi4yMDR2LS40NjAzYzAtMS4wNDE2LjcyMS0yLjEzMSAxLjcwNzMtMi4xMzEuOTg2NC4wIDEuNjQyNSAxLjAzMSAxLjU0NDMgMi4yNDkyaC0yLjk1NiIgLz48L2c+PC9zdmc+)]{.kbd
.flexsearch-button-cmd-key}[to close]{.flexsearch-key-label}

cancel


-   [*Home*](../../docs){itemprop="item"}
-   [[Getting
    started]{itemprop="name"}](https://localai.io/docs/getting-started/){itemprop="item"}
-   [Run with container images]{itemprop="name"}

On this page

-   -   -   
    -   [All-in-one images](index.html#all-in-one-images)
        -   [Usage](index.html#usage)
        -   [Available AIO images](index.html#available-aio-images)
        -   [Available environment
            variables](index.html#available-environment-variables)
    -   [Standard container
        images](index.html#standard-container-images)
    -   [See Also](index.html#see-also)

Table of Contents

-   -   -   
    -   [All-in-one images](index.html#all-in-one-images)
        -   [Usage](index.html#usage)
        -   [Available AIO images](index.html#available-aio-images)
        -   [Available environment
            variables](index.html#available-environment-variables)
    -   [Standard container
        images](index.html#standard-container-images)
    -   [See Also](index.html#see-also)

*article*

# Run with container images {#run-with-container-images .content-title .mb-0}

LocalAI provides a variety of images to support different environments.
These images are available on
[quay.io![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdib3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48cGF0aCBmaWxsPSJjdXJyZW50Y29sb3IiIGQ9Ik0xNCA1Yy0uNTUyLjAtMS0uNDQ4LTEtMXMuNDQ4LTEgMS0xaDZjLjU1Mi4wIDEgLjQ0OCAxIDF2NmMwIC41NTItLjQ0OCAxLTEgMXMtMS0uNDQ4LTEtMVY2LjQxNGwtNy4yOTMgNy4yOTNjLS4zOTEuMzktMS4wMjQuMzktMS40MTQuMC0uMzkxLS4zOTEtLjM5MS0xLjAyNC4wLTEuNDE0TDE3LjU4NiA1SDE0ek01IDdjLS41NTIuMC0xIC40NDgtMSAxdjExYzAgLjU1Mi40NDggMSAxIDFoMTFjLjU1Mi4wIDEtLjQ0OCAxLTF2LTQuNTYzYzAtLjU1Mi40NDgtMSAxLTFzMSAuNDQ4IDEgMVYxOWMwIDEuNjU3LTEuMzQzIDMtMyAzSDVjLTEuNjU3LjAtMy0xLjM0My0zLTNWOGMwLTEuNjU3IDEuMzQzLTMgMy0zaDQuNTYzYy41NTIuMCAxIC40NDggMSAxcy0uNDQ4IDEtMSAxSDV6IiAvPjwvc3ZnPg==)](https://quay.io/repository/go-skynet/local-ai?tab=tags){rel="external"
target="_blank"} and [Docker
Hub![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdib3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48cGF0aCBmaWxsPSJjdXJyZW50Y29sb3IiIGQ9Ik0xNCA1Yy0uNTUyLjAtMS0uNDQ4LTEtMXMuNDQ4LTEgMS0xaDZjLjU1Mi4wIDEgLjQ0OCAxIDF2NmMwIC41NTItLjQ0OCAxLTEgMXMtMS0uNDQ4LTEtMVY2LjQxNGwtNy4yOTMgNy4yOTNjLS4zOTEuMzktMS4wMjQuMzktMS40MTQuMC0uMzkxLS4zOTEtLjM5MS0xLjAyNC4wLTEuNDE0TDE3LjU4NiA1SDE0ek01IDdjLS41NTIuMC0xIC40NDgtMSAxdjExYzAgLjU1Mi40NDggMSAxIDFoMTFjLjU1Mi4wIDEtLjQ0OCAxLTF2LTQuNTYzYzAtLjU1Mi40NDgtMSAxLTFzMSAuNDQ4IDEgMVYxOWMwIDEuNjU3LTEuMzQzIDMtMyAzSDVjLTEuNjU3LjAtMy0xLjM0My0zLTNWOGMwLTEuNjU3IDEuMzQzLTMgMy0zaDQuNTYzYy41NTIuMCAxIC40NDggMSAxcy0uNDQ4IDEtMSAxSDV6IiAvPjwvc3ZnPg==)](https://hub.docker.com/r/localai/localai){rel="external"
target="_blank"}.

All-in-One images comes with a pre-configured set of models and
backends, standard images instead do not have any model pre-configured
and installed.

For GPU Acceleration support for Nvidia video graphic cards, use the
Nvidia/CUDA images, if you don't have a GPU, use the CPU images. If you
have AMD or Mac Silicon, see the [build section](../build/index.html).

üí°

**Available Images Types**:

-   Images ending with `-core` are smaller images without predownload
    python dependencies. Use these images if you plan to use
    `llama.cpp`, `stablediffusion-ncn` or `rwkv` backends - if you are
    not sure which one to use, do **not** use these images.

-   Images containing the `aio` tag are all-in-one images with all the
    features enabled, and come with an opinionated set of configuration.

-   FFMpeg is **not** included in the default images due to [its
    licensing![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdib3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48cGF0aCBmaWxsPSJjdXJyZW50Y29sb3IiIGQ9Ik0xNCA1Yy0uNTUyLjAtMS0uNDQ4LTEtMXMuNDQ4LTEgMS0xaDZjLjU1Mi4wIDEgLjQ0OCAxIDF2NmMwIC41NTItLjQ0OCAxLTEgMXMtMS0uNDQ4LTEtMVY2LjQxNGwtNy4yOTMgNy4yOTNjLS4zOTEuMzktMS4wMjQuMzktMS40MTQuMC0uMzkxLS4zOTEtLjM5MS0xLjAyNC4wLTEuNDE0TDE3LjU4NiA1SDE0ek01IDdjLS41NTIuMC0xIC40NDgtMSAxdjExYzAgLjU1Mi40NDggMSAxIDFoMTFjLjU1Mi4wIDEtLjQ0OCAxLTF2LTQuNTYzYzAtLjU1Mi40NDgtMSAxLTFzMSAuNDQ4IDEgMVYxOWMwIDEuNjU3LTEuMzQzIDMtMyAzSDVjLTEuNjU3LjAtMy0xLjM0My0zLTNWOGMwLTEuNjU3IDEuMzQzLTMgMy0zaDQuNTYzYy41NTIuMCAxIC40NDggMSAxcy0uNDQ4IDEtMSAxSDV6IiAvPjwvc3ZnPg==)](https://www.ffmpeg.org/legal.html){rel="external"
    target="_blank"}. If you need FFMpeg, use the images ending with
    `-ffmpeg`. Note that `ffmpeg` is needed in case of using
    `audio-to-text` LocalAI's features.

-   If using old and outdated CPUs and no GPUs you might need to set
    `REBUILD` to `true` as environment variable along with options to
    disable the flags which your CPU does not support, however note that
    inference will perform poorly and slow. See also [flagset
    compatibility](../build/index.html#cpu-flagset-compatibility).

#### Prerequisites [*link*](index.html#prerequisites){.anchor aria-hidden="true"} {#prerequisites}

Before you begin, ensure you have a container engine installed if you
are not using the binaries. Suitable options include Docker or Podman.
For installation instructions, refer to the following guides:

-   [Install Docker Desktop (Mac, Windows,
    Linux)![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdib3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48cGF0aCBmaWxsPSJjdXJyZW50Y29sb3IiIGQ9Ik0xNCA1Yy0uNTUyLjAtMS0uNDQ4LTEtMXMuNDQ4LTEgMS0xaDZjLjU1Mi4wIDEgLjQ0OCAxIDF2NmMwIC41NTItLjQ0OCAxLTEgMXMtMS0uNDQ4LTEtMVY2LjQxNGwtNy4yOTMgNy4yOTNjLS4zOTEuMzktMS4wMjQuMzktMS40MTQuMC0uMzkxLS4zOTEtLjM5MS0xLjAyNC4wLTEuNDE0TDE3LjU4NiA1SDE0ek01IDdjLS41NTIuMC0xIC40NDgtMSAxdjExYzAgLjU1Mi40NDggMSAxIDFoMTFjLjU1Mi4wIDEtLjQ0OCAxLTF2LTQuNTYzYzAtLjU1Mi40NDgtMSAxLTFzMSAuNDQ4IDEgMVYxOWMwIDEuNjU3LTEuMzQzIDMtMyAzSDVjLTEuNjU3LjAtMy0xLjM0My0zLTNWOGMwLTEuNjU3IDEuMzQzLTMgMy0zaDQuNTYzYy41NTIuMCAxIC40NDggMSAxcy0uNDQ4IDEtMSAxSDV6IiAvPjwvc3ZnPg==)](https://docs.docker.com/get-docker/){rel="external"
    target="_blank"}
-   [Install Podman
    (Linux)![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdib3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48cGF0aCBmaWxsPSJjdXJyZW50Y29sb3IiIGQ9Ik0xNCA1Yy0uNTUyLjAtMS0uNDQ4LTEtMXMuNDQ4LTEgMS0xaDZjLjU1Mi4wIDEgLjQ0OCAxIDF2NmMwIC41NTItLjQ0OCAxLTEgMXMtMS0uNDQ4LTEtMVY2LjQxNGwtNy4yOTMgNy4yOTNjLS4zOTEuMzktMS4wMjQuMzktMS40MTQuMC0uMzkxLS4zOTEtLjM5MS0xLjAyNC4wLTEuNDE0TDE3LjU4NiA1SDE0ek01IDdjLS41NTIuMC0xIC40NDgtMSAxdjExYzAgLjU1Mi40NDggMSAxIDFoMTFjLjU1Mi4wIDEtLjQ0OCAxLTF2LTQuNTYzYzAtLjU1Mi40NDgtMSAxLTFzMSAuNDQ4IDEgMVYxOWMwIDEuNjU3LTEuMzQzIDMtMyAzSDVjLTEuNjU3LjAtMy0xLjM0My0zLTNWOGMwLTEuNjU3IDEuMzQzLTMgMy0zaDQuNTYzYy41NTIuMCAxIC40NDggMSAxcy0uNDQ4IDEtMSAxSDV6IiAvPjwvc3ZnPg==)](https://podman.io/getting-started/installation){rel="external"
    target="_blank"}
-   [Install Docker engine
    (Servers)![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdib3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48cGF0aCBmaWxsPSJjdXJyZW50Y29sb3IiIGQ9Ik0xNCA1Yy0uNTUyLjAtMS0uNDQ4LTEtMXMuNDQ4LTEgMS0xaDZjLjU1Mi4wIDEgLjQ0OCAxIDF2NmMwIC41NTItLjQ0OCAxLTEgMXMtMS0uNDQ4LTEtMVY2LjQxNGwtNy4yOTMgNy4yOTNjLS4zOTEuMzktMS4wMjQuMzktMS40MTQuMC0uMzkxLS4zOTEtLjM5MS0xLjAyNC4wLTEuNDE0TDE3LjU4NiA1SDE0ek01IDdjLS41NTIuMC0xIC40NDgtMSAxdjExYzAgLjU1Mi40NDggMSAxIDFoMTFjLjU1Mi4wIDEtLjQ0OCAxLTF2LTQuNTYzYzAtLjU1Mi40NDgtMSAxLTFzMSAuNDQ4IDEgMVYxOWMwIDEuNjU3LTEuMzQzIDMtMyAzSDVjLTEuNjU3LjAtMy0xLjM0My0zLTNWOGMwLTEuNjU3IDEuMzQzLTMgMy0zaDQuNTYzYy41NTIuMCAxIC40NDggMSAxcy0uNDQ4IDEtMSAxSDV6IiAvPjwvc3ZnPg==)](https://docs.docker.com/engine/install/#get-started){rel="external"
    target="_blank"}

üí°

**Hardware Requirements:** The hardware requirements for LocalAI vary
based on the model size and quantization method used. For performance
benchmarks with different backends, such as `llama.cpp`, visit [this
link![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdib3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48cGF0aCBmaWxsPSJjdXJyZW50Y29sb3IiIGQ9Ik0xNCA1Yy0uNTUyLjAtMS0uNDQ4LTEtMXMuNDQ4LTEgMS0xaDZjLjU1Mi4wIDEgLjQ0OCAxIDF2NmMwIC41NTItLjQ0OCAxLTEgMXMtMS0uNDQ4LTEtMVY2LjQxNGwtNy4yOTMgNy4yOTNjLS4zOTEuMzktMS4wMjQuMzktMS40MTQuMC0uMzkxLS4zOTEtLjM5MS0xLjAyNC4wLTEuNDE0TDE3LjU4NiA1SDE0ek01IDdjLS41NTIuMC0xIC40NDgtMSAxdjExYzAgLjU1Mi40NDggMSAxIDFoMTFjLjU1Mi4wIDEtLjQ0OCAxLTF2LTQuNTYzYzAtLjU1Mi40NDgtMSAxLTFzMSAuNDQ4IDEgMVYxOWMwIDEuNjU3LTEuMzQzIDMtMyAzSDVjLTEuNjU3LjAtMy0xLjM0My0zLTNWOGMwLTEuNjU3IDEuMzQzLTMgMy0zaDQuNTYzYy41NTIuMCAxIC40NDggMSAxcy0uNDQ4IDEtMSAxSDV6IiAvPjwvc3ZnPg==)](https://github.com/ggerganov/llama.cpp#memorydisk-requirements){rel="external"
target="_blank"}. The `rwkv` backend is noted for its lower resource
consumption.

## All-in-one images [*link*](index.html#all-in-one-images){.anchor aria-hidden="true"} {#all-in-one-images}

All-In-One images are images that come pre-configured with a set of
models and backends to fully leverage almost all the LocalAI featureset.
These images are available for both CPU and GPU environments. The AIO
images are designed to be easy to use and requires no configuration.
Models configuration can be found
[here![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdib3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48cGF0aCBmaWxsPSJjdXJyZW50Y29sb3IiIGQ9Ik0xNCA1Yy0uNTUyLjAtMS0uNDQ4LTEtMXMuNDQ4LTEgMS0xaDZjLjU1Mi4wIDEgLjQ0OCAxIDF2NmMwIC41NTItLjQ0OCAxLTEgMXMtMS0uNDQ4LTEtMVY2LjQxNGwtNy4yOTMgNy4yOTNjLS4zOTEuMzktMS4wMjQuMzktMS40MTQuMC0uMzkxLS4zOTEtLjM5MS0xLjAyNC4wLTEuNDE0TDE3LjU4NiA1SDE0ek01IDdjLS41NTIuMC0xIC40NDgtMSAxdjExYzAgLjU1Mi40NDggMSAxIDFoMTFjLjU1Mi4wIDEtLjQ0OCAxLTF2LTQuNTYzYzAtLjU1Mi40NDgtMSAxLTFzMSAuNDQ4IDEgMVYxOWMwIDEuNjU3LTEuMzQzIDMtMyAzSDVjLTEuNjU3LjAtMy0xLjM0My0zLTNWOGMwLTEuNjU3IDEuMzQzLTMgMy0zaDQuNTYzYy41NTIuMCAxIC40NDggMSAxcy0uNDQ4IDEtMSAxSDV6IiAvPjwvc3ZnPg==)](https://github.com/mudler/LocalAI/tree/master/aio){rel="external"
target="_blank"} separated by size.

In the AIO images there are models configured with the names of OpenAI
models, however, they are really backed by Open Source models. You can
find the table below

  Category            Model name                 Real model (CPU)                            Real model (GPU)
  ------------------- -------------------------- ------------------------------------------- ------------------------
  Text Generation     `gpt-4`                    `phi-2`                                     `hermes-2-pro-mistral`
  Multimodal Vision   `gpt-4-vision-preview`     `bakllava`                                  `llava-1.6-mistral`
  Image Generation    `stablediffusion`          `stablediffusion`                           `dreamshaper-8`
  Speech to Text      `whisper-1`                `whisper` with `whisper-base` model         \<= same
  Text to Speech      `tts-1`                    `en-us-amy-low.onnx` from `rhasspy/piper`   \<= same
  Embeddings          `text-embedding-ada-002`   `all-MiniLM-L6-v2` in Q4                    `all-MiniLM-L6-v2`

### Usage [*link*](index.html#usage){.anchor aria-hidden="true"} {#usage}

Select the image (CPU or GPU) and start the container with Docker:

``` {#c9f7bef .language-bash}
  # CPU example
docker run -p 8080:8080 --name local-ai -ti localai/localai:latest-aio-cpu
# For Nvidia GPUs:
# docker run -p 8080:8080 --gpus all --name local-ai -ti localai/localai:latest-aio-gpu-nvidia-cuda-11
# docker run -p 8080:8080 --gpus all --name local-ai -ti localai/localai:latest-aio-gpu-nvidia-cuda-12
  
```

LocalAI will automatically download all the required models, and the API
will be available at
[localhost:8080![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdib3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48cGF0aCBmaWxsPSJjdXJyZW50Y29sb3IiIGQ9Ik0xNCA1Yy0uNTUyLjAtMS0uNDQ4LTEtMXMuNDQ4LTEgMS0xaDZjLjU1Mi4wIDEgLjQ0OCAxIDF2NmMwIC41NTItLjQ0OCAxLTEgMXMtMS0uNDQ4LTEtMVY2LjQxNGwtNy4yOTMgNy4yOTNjLS4zOTEuMzktMS4wMjQuMzktMS40MTQuMC0uMzkxLS4zOTEtLjM5MS0xLjAyNC4wLTEuNDE0TDE3LjU4NiA1SDE0ek01IDdjLS41NTIuMC0xIC40NDgtMSAxdjExYzAgLjU1Mi40NDggMSAxIDFoMTFjLjU1Mi4wIDEtLjQ0OCAxLTF2LTQuNTYzYzAtLjU1Mi40NDgtMSAxLTFzMSAuNDQ4IDEgMVYxOWMwIDEuNjU3LTEuMzQzIDMtMyAzSDVjLTEuNjU3LjAtMy0xLjM0My0zLTNWOGMwLTEuNjU3IDEuMzQzLTMgMy0zaDQuNTYzYy41NTIuMCAxIC40NDggMSAxcy0uNDQ4IDEtMSAxSDV6IiAvPjwvc3ZnPg==)](http://localhost:8080/v1/models){rel="external"
target="_blank"}.

Or with a docker-compose file:

``` {#9657d0d .language-yaml}
  version: "3.9"
services:
  api:
    image: localai/localai:latest-aio-cpu
    # For a specific version:
    # image: localai/localai:v2.27.0-aio-cpu
    # For Nvidia GPUs decomment one of the following (cuda11 or cuda12):
    # image: localai/localai:v2.27.0-aio-gpu-nvidia-cuda-11
    # image: localai/localai:v2.27.0-aio-gpu-nvidia-cuda-12
    # image: localai/localai:latest-aio-gpu-nvidia-cuda-11
    # image: localai/localai:latest-aio-gpu-nvidia-cuda-12
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/readyz"]
      interval: 1m
      timeout: 20m
      retries: 5
    ports:
      - 8080:8080
    environment:
      - DEBUG=true
      # ...
    volumes:
      - ./models:/build/models:cached
    # decomment the following piece if running with Nvidia GPUs
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]
  
```

üí°

**Models caching**: The **AIO** image will download the needed models on
the first run if not already present and store those in `/build/models`
inside the container. The AIO models will be automatically updated with
new versions of AIO images.

You can change the directory inside the container by specifying a
`MODELS_PATH` environment variable (or `--models-path`).

If you want to use a named model or a local directory, you can mount it
as a volume to `/build/models`:

``` {#a9236bf .language-bash}
  docker run -p 8080:8080 --name local-ai -ti -v $PWD/models:/build/models localai/localai:latest-aio-cpu
  
```

or associate a volume:

``` {#6e9f5db .language-bash}
  docker volume create localai-models
docker run -p 8080:8080 --name local-ai -ti -v localai-models:/build/models localai/localai:latest-aio-cpu
  
```

### Available AIO images [*link*](index.html#available-aio-images){.anchor aria-hidden="true"} {#available-aio-images}

  Description                              Quay                                                         Docker Hub
  ---------------------------------------- ------------------------------------------------------------ -------------------------------------------------
  Latest images for CPU                    `quay.io/go-skynet/local-ai:latest-aio-cpu`                  `localai/localai:latest-aio-cpu`
  Versioned image (e.g. for CPU)           `quay.io/go-skynet/local-ai:v2.27.0-aio-cpu`                 `localai/localai:v2.27.0-aio-cpu`
  Latest images for Nvidia GPU (CUDA11)    `quay.io/go-skynet/local-ai:latest-aio-gpu-nvidia-cuda-11`   `localai/localai:latest-aio-gpu-nvidia-cuda-11`
  Latest images for Nvidia GPU (CUDA12)    `quay.io/go-skynet/local-ai:latest-aio-gpu-nvidia-cuda-12`   `localai/localai:latest-aio-gpu-nvidia-cuda-12`
  Latest images for AMD GPU                `quay.io/go-skynet/local-ai:latest-aio-gpu-hipblas`          `localai/localai:latest-aio-gpu-hipblas`
  Latest images for Intel GPU (sycl f16)   `quay.io/go-skynet/local-ai:latest-aio-gpu-intel-f16`        `localai/localai:latest-aio-gpu-intel-f16`
  Latest images for Intel GPU (sycl f32)   `quay.io/go-skynet/local-ai:latest-aio-gpu-intel-f32`        `localai/localai:latest-aio-gpu-intel-f32`

### Available environment variables [*link*](index.html#available-environment-variables){.anchor aria-hidden="true"} {#available-environment-variables}

The AIO Images are inheriting the same environment variables as the base
images and the environment of LocalAI (that you can inspect by calling
`--help`). However, it supports additional environment variables
available only from the container image

  Variable    Default         Description
  ----------- --------------- -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  `PROFILE`   Auto-detected   The size of the model to use. Available: `cpu`, `gpu-8g`
  `MODELS`    Auto-detected   A list of models YAML Configuration file URI/URL (see also [running models](https://localai.io/docs/getting-started/models/){bs-delay="{\"hide\":300,\"show\":550}" bs-html="true" bs-title="<a href='/docs/getting-started/models/'><p>GETTING STARTED</p><strong>Install and Run Models</strong><br></a>" bs-toggle="tooltip"})

## Standard container images [*link*](index.html#standard-container-images){.anchor aria-hidden="true"} {#standard-container-images}

Standard container images do not have pre-installed models.

Images are available with and without python dependencies. Note that
images with python dependencies are bigger (in order of 17GB).

Images with `core` in the tag are smaller and do not contain any python
dependencies.

[Vanilla / CPU Images]{#aedbcfTab .nav-link .active bs-toggle="tab"
bs-target="#aedbcf" type="button" role="tab" aria-controls="aedbcf"
aria-selected="true"} [GPU Images CUDA 11]{#becdfaTab .nav-link
bs-toggle="tab" bs-target="#becdfa" type="button" role="tab"
aria-controls="becdfa" aria-selected="true"} [GPU Images CUDA
12]{#fbceadTab .nav-link bs-toggle="tab" bs-target="#fbcead"
type="button" role="tab" aria-controls="fbcead" aria-selected="true"}
[Intel GPU (sycl f16)]{#facbedTab .nav-link bs-toggle="tab"
bs-target="#facbed" type="button" role="tab" aria-controls="facbed"
aria-selected="true"} [Intel GPU (sycl f32)]{#cbadefTab .nav-link
bs-toggle="tab" bs-target="#cbadef" type="button" role="tab"
aria-controls="cbadef" aria-selected="true"} [AMD GPU]{#ecabdfTab
.nav-link bs-toggle="tab" bs-target="#ecabdf" type="button" role="tab"
aria-controls="ecabdf" aria-selected="true"} [Vulkan Images]{#dbcfaeTab
.nav-link bs-toggle="tab" bs-target="#dbcfae" type="button" role="tab"
aria-controls="dbcfae" aria-selected="true"} [Nvidia Linux for
tegra]{#ecabdfTab .nav-link bs-toggle="tab" bs-target="#ecabdf"
type="button" role="tab" aria-controls="ecabdf" aria-selected="true"}

  Description                                   Quay                                               Docker Hub
  --------------------------------------------- -------------------------------------------------- ---------------------------------------
  Latest images from the branch (development)   `quay.io/go-skynet/local-ai:master`                `localai/localai:master`
  Latest tag                                    `quay.io/go-skynet/local-ai:latest-cpu`            `localai/localai:latest-cpu`
  Versioned image                               `quay.io/go-skynet/local-ai:v2.27.0`               `localai/localai:v2.27.0`
  Versioned image including FFMpeg              `quay.io/go-skynet/local-ai:v2.27.0-ffmpeg`        `localai/localai:v2.27.0-ffmpeg`
  Versioned image including FFMpeg, no python   `quay.io/go-skynet/local-ai:v2.27.0-ffmpeg-core`   `localai/localai:v2.27.0-ffmpeg-core`

  Description                                   Quay                                                             Docker Hub
  --------------------------------------------- ---------------------------------------------------------------- -----------------------------------------------------
  Latest images from the branch (development)   `quay.io/go-skynet/local-ai:master-cublas-cuda11`                `localai/localai:master-cublas-cuda11`
  Latest tag                                    `quay.io/go-skynet/local-ai:latest-gpu-nvidia-cuda-11`           `localai/localai:latest-gpu-nvidia-cuda-11`
  Versioned image                               `quay.io/go-skynet/local-ai:v2.27.0-cublas-cuda11`               `localai/localai:v2.27.0-cublas-cuda11`
  Versioned image including FFMpeg              `quay.io/go-skynet/local-ai:v2.27.0-cublas-cuda11-ffmpeg`        `localai/localai:v2.27.0-cublas-cuda11-ffmpeg`
  Versioned image including FFMpeg, no python   `quay.io/go-skynet/local-ai:v2.27.0-cublas-cuda11-ffmpeg-core`   `localai/localai:v2.27.0-cublas-cuda11-ffmpeg-core`

  Description                                   Quay                                                             Docker Hub
  --------------------------------------------- ---------------------------------------------------------------- -----------------------------------------------------
  Latest images from the branch (development)   `quay.io/go-skynet/local-ai:master-cublas-cuda12`                `localai/localai:master-cublas-cuda12`
  Latest tag                                    `quay.io/go-skynet/local-ai:latest-gpu-nvidia-cuda-12`           `localai/localai:latest-gpu-nvidia-cuda-12`
  Versioned image                               `quay.io/go-skynet/local-ai:v2.27.0-cublas-cuda12`               `localai/localai:v2.27.0-cublas-cuda12`
  Versioned image including FFMpeg              `quay.io/go-skynet/local-ai:v2.27.0-cublas-cuda12-ffmpeg`        `localai/localai:v2.27.0-cublas-cuda12-ffmpeg`
  Versioned image including FFMpeg, no python   `quay.io/go-skynet/local-ai:v2.27.0-cublas-cuda12-ffmpeg-core`   `localai/localai:v2.27.0-cublas-cuda12-ffmpeg-core`

  Description                                   Quay                                                        Docker Hub
  --------------------------------------------- ----------------------------------------------------------- ------------------------------------------------
  Latest images from the branch (development)   `quay.io/go-skynet/local-ai:master-sycl-f16`                `localai/localai:master-sycl-f16`
  Latest tag                                    `quay.io/go-skynet/local-ai:latest-gpu-intel-f16`           `localai/localai:latest-gpu-intel-f16`
  Versioned image                               `quay.io/go-skynet/local-ai:v2.27.0-sycl-f16-core`          `localai/localai:v2.27.0-sycl-f16-core`
  Versioned image including FFMpeg              `quay.io/go-skynet/local-ai:v2.27.0-sycl-f16-ffmpeg`        `localai/localai:v2.27.0-sycl-f16-ffmpeg`
  Versioned image including FFMpeg, no python   `quay.io/go-skynet/local-ai:v2.27.0-sycl-f16-ffmpeg-core`   `localai/localai:v2.27.0-sycl-f16-ffmpeg-core`

  Description                                   Quay                                                        Docker Hub
  --------------------------------------------- ----------------------------------------------------------- ------------------------------------------------
  Latest images from the branch (development)   `quay.io/go-skynet/local-ai:master-sycl-f32`                `localai/localai:master-sycl-f32`
  Latest tag                                    `quay.io/go-skynet/local-ai:latest-gpu-intel-f32`           `localai/localai:latest-gpu-intel-f32`
  Versioned image                               `quay.io/go-skynet/local-ai:v2.27.0-sycl-f32-core`          `localai/localai:v2.27.0-sycl-f32-core`
  Versioned image including FFMpeg              `quay.io/go-skynet/local-ai:v2.27.0-sycl-f32-ffmpeg`        `localai/localai:v2.27.0-sycl-f32-ffmpeg`
  Versioned image including FFMpeg, no python   `quay.io/go-skynet/local-ai:v2.27.0-sycl-f32-ffmpeg-core`   `localai/localai:v2.27.0-sycl-f32-ffmpeg-core`

  Description                                   Quay                                                       Docker Hub
  --------------------------------------------- ---------------------------------------------------------- -----------------------------------------------
  Latest images from the branch (development)   `quay.io/go-skynet/local-ai:master-hipblas`                `localai/localai:master-hipblas`
  Latest tag                                    `quay.io/go-skynet/local-ai:latest-gpu-hipblas`            `localai/localai:latest-gpu-hipblas`
  Versioned image                               `quay.io/go-skynet/local-ai:v2.27.0-hipblas`               `localai/localai:v2.27.0-hipblas`
  Versioned image including FFMpeg              `quay.io/go-skynet/local-ai:v2.27.0-hipblas-ffmpeg`        `localai/localai:v2.27.0-hipblas-ffmpeg`
  Versioned image including FFMpeg, no python   `quay.io/go-skynet/local-ai:v2.27.0-hipblas-ffmpeg-core`   `localai/localai:v2.27.0-hipblas-ffmpeg-core`

  Description                                   Quay                                                      Docker Hub
  --------------------------------------------- --------------------------------------------------------- ----------------------------------------------
  Latest images from the branch (development)   `quay.io/go-skynet/local-ai: master-vulkan-ffmpeg-core`   `localai/localai: master-vulkan-ffmpeg-core`
  Latest tag                                    `quay.io/go-skynet/local-ai: latest-vulkan-ffmpeg-core`   `localai/localai: latest-vulkan-ffmpeg-core`
  Versioned image including FFMpeg, no python   `quay.io/go-skynet/local-ai:v2.27.0-vulkan-fmpeg-core`    `localai/localai:v2.27.0-vulkan-fmpeg-core`

These images are compatible with Nvidia ARM64 devices, such as the
Jetson Nano, Jetson Xavier NX, and Jetson AGX Xavier. For more
information, see the [Nvidia L4T
guide](https://localai.io/docs/reference/nvidia-l4t/){bs-delay="{\"hide\":300,\"show\":550}"
bs-html="true"
bs-title="<a href='/docs/reference/nvidia-l4t/'><p>REFERENCES</p><strong>Running on Nvidia ARM64</strong><br></a>"
bs-toggle="tooltip"}.

  Description                                   Quay                                                         Docker Hub
  --------------------------------------------- ------------------------------------------------------------ -------------------------------------------------
  Latest images from the branch (development)   `quay.io/go-skynet/local-ai:master-nvidia-l4t-arm64-core`    `localai/localai:master-nvidia-l4t-arm64-core`
  Latest tag                                    `quay.io/go-skynet/local-ai:latest-nvidia-l4t-arm64-core`    `localai/localai:latest-nvidia-l4t-arm64-core`
  Versioned image                               `quay.io/go-skynet/local-ai:v2.27.0-nvidia-l4t-arm64-core`   `localai/localai:v2.27.0-nvidia-l4t-arm64-core`

## See Also [*link*](index.html#see-also){.anchor aria-hidden="true"} {#see-also}

-   [GPU acceleration](../../features/gpu-acceleration/index.html)

[[![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjAiIGhlaWdodD0iMjAiIHZpZXdib3g9IjAgMCAzMiAzMiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiBmaWxsPSJjdXJyZW50Y29sb3IiPjxwYXRoIGQ9Ik0xNiAuMzk2Yy04LjgzOS4wLTE2IDcuMTY3LTE2IDE2IDAgNy4wNzMgNC41ODQgMTMuMDY4IDEwLjkzNyAxNS4xODMuODAzLjE1MSAxLjA5My0uMzQ0IDEuMDkzLS43NzIuMC0uMzgtLjAwOS0xLjM4NS0uMDE1LTIuNzE5LTQuNDUzLjk2NC01LjM5MS0yLjE1MS01LjM5MS0yLjE1MS0uNzI5LTEuODQ0LTEuNzgxLTIuMzM5LTEuNzgxLTIuMzM5LTEuNDQ4LS45ODkuMTE1LS45NjguMTE1LS45NjggMS42MDQuMTA5IDIuNDQ4IDEuNjQ1IDIuNDQ4IDEuNjQ1IDEuNDI3IDIuNDQ4IDMuNzQ0IDEuNzQgNC42NjEgMS4zMjguMTQtMS4wMzEuNTU3LTEuNzQgMS4wMTEtMi4xMzUtMy41NTItLjQwMS03LjI4Ny0xLjc3Ni03LjI4Ny03LjkwNy4wLTEuNzUxLjYyLTMuMTc3IDEuNjQ1LTQuMjk3LS4xNzctLjQwMS0uNzE5LTIuMDMxLjE0MS00LjIzNS4wLjAgMS4zMzktLjQyNyA0LjQgMS42NDEgMS4yODEtLjM1NSAyLjY0MS0uNTMyIDQtLjU0MSAxLjM2LjAwOSAyLjcxOS4xODcgNCAuNTQxIDMuMDQzLTIuMDY4IDQuMzgxLTEuNjQxIDQuMzgxLTEuNjQxLjg1OSAyLjIwNC4zMTcgMy44MzMuMTYxIDQuMjM1IDEuMDE1IDEuMTIgMS42MzUgMi41NDcgMS42MzUgNC4yOTcuMCA2LjE0NS0zLjc0IDcuNS03LjI5NiA3Ljg5MS41NTYuNDc5IDEuMDc3IDEuNDY0IDEuMDc3IDIuOTU5LjAgMi4xNC0uMDIgMy44NjQtLjAyIDQuMzg1LjAuNDE2LjI4LjkxNiAxLjEwNC43NTUgNi40LTIuMDkzIDEwLjk3OS04LjA5MyAxMC45NzktMTUuMTU2LjAtOC44MzMtNy4xNjEtMTYtMTYtMTZ6IiAvPjwvc3ZnPg==)]{.me-1
.align-text-bottom}Edit this
page](https://github.com/mudler/LocalAI/blob/master/docs/content/docs/getting-started/container-images.md){alt="Run with container images"
rel="noopener noreferrer" target="_blank"}

Last updated [30 Jan 2025, 00:03 +0100 ]{#relativetime
authdate="2025-01-30T00:03:01+0100" title="30 Jan 2025, 00:03 +0100"}.
[history]{.material-icons .size-20 .align-text-bottom .opacity-75}

<div>

------------------------------------------------------------------------

[](../build/index.html)

*navigate_before* Build LocalAI from source

[](../kubernetes/index.html){.ms-auto}

Run with Kubernetes *navigate_next*

</div>

¬© 2023-2025 [Ettore Di Giacinto](https://mudler.pm){target="_blank"}

![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiPjxwYXRoIGQ9Ik0xMiAxMC4yMjRsLTYuMyA2LjMtMS4zOC0xLjM3MkwxMiA3LjQ3Mmw3LjY4IDcuNjgtMS4zOCAxLjM3NnoiIHN0eWxlPSJmaWxsOiNmZmYiIC8+PC9zdmc+)
