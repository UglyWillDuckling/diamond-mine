-   [![](https://github.com/go-skynet/LocalAI/assets/2420543/0966aa2a-166e-4f99-a3e5-6c915fc997dd){style="width:calc(65%);height:calc(65%)"}](../../index.html){aria-label="HomePage"
    alt="HomePage"}

    LocalAI

-   [![](https://img.shields.io/github/release/go-skynet/LocalAI?&label=Latest&style=for-the-badge)](https://github.com/go-skynet/LocalAI/releases)

-   [![](https://img.shields.io/badge/dockerhub-images-important.svg?logo=Docker)](https://hub.docker.com/r/localai/localai){target="_blank"}
    [![](https://img.shields.io/badge/quay.io-images-important.svg?)](https://quay.io/repository/go-skynet/local-ai?tab=tags&tag=latest){target="_blank"}

-   [*info* Overview](../../index.html){.sidebar-root-link}
-   *rocket_launch* Getting started

    -   [Quickstart](../getting_started/index.html){.sidebar-nested-link}
    -   [Install and Run
        Models](https://localai.io/docs/getting-started/models/){.sidebar-nested-link}
    -   [Try it out](../try/index.html){.sidebar-nested-link}
    -   [Customizing the
        Model](https://localai.io/docs/getting-started/customize-model/){.sidebar-nested-link}
    -   [Build LocalAI from source](index.html){.sidebar-nested-link}
    -   [Run with container
        images](../container/index.html){.sidebar-nested-link}
    -   [Run with
        Kubernetes](../kubernetes/index.html){.sidebar-nested-link}
-   [*newspaper* News](../news/index.html){.sidebar-root-link}
-   *feature_search* Features

    -   [‚ö° GPU
        acceleration](../../features/gpu-acceleration/index.html){.sidebar-nested-link}
    -   [üìñ Text generation
        (GPT)](../../features/text-generation/index.html){.sidebar-nested-link}
    -   [üìà
        Reranker](../../features/reranker/index.html){.sidebar-nested-link}
    -   [üó£ Text to audio
        (TTS)](../../features/text-to-audio/index.html){.sidebar-nested-link}
    -   [üé® Image
        generation](../../features/image-generation/index.html){.sidebar-nested-link}
    -   [üß†
        Embeddings](../../features/embeddings/index.html){.sidebar-nested-link}
    -   [ü•Ω GPT
        Vision](../../features/gpt-vision/index.html){.sidebar-nested-link}
    -   [‚úçÔ∏è Constrained
        Grammars](../../features/constrained_grammars/index.html){.sidebar-nested-link}
    -   [üÜïüñß Distributed
        Inference](../../features/distribute/index.html){.sidebar-nested-link}
    -   [üîà Audio to
        text](../../features/audio-to-text/index.html){.sidebar-nested-link}
    -   [üî• OpenAI functions and
        tools](../../features/openai-functions/index.html){.sidebar-nested-link}
    -   [üíæ Stores](../../stores/index.html){.sidebar-nested-link}
    -   [üñºÔ∏è Model
        gallery](../../models/index.html){.sidebar-nested-link}
-   [*sync*
    Integrations](https://localai.io/docs/integrations/){.sidebar-root-link}
-   *settings* Advanced

    -   [Advanced
        usage](../../advanced/index.html){.sidebar-nested-link}
    -   [Fine-tuning LLMs for text
        generation](https://localai.io/docs/advanced/fine-tuning/){.sidebar-nested-link}
    -   [Installer
        options](https://localai.io/docs/advanced/installer/){.sidebar-nested-link}
-   *menu_book* References

    -   [Model compatibility
        table](../../model-compatibility/index.html){.sidebar-nested-link}
    -   [Architecture](https://localai.io/docs/reference/architecture/){.sidebar-nested-link}
    -   [LocalAI
        binaries](https://localai.io/docs/reference/binaries/){.sidebar-nested-link}
    -   [Running on Nvidia
        ARM64](https://localai.io/docs/reference/nvidia-l4t/){.sidebar-nested-link}
-   [*quiz* FAQ](../../faq/index.html){.sidebar-root-link}

[](../../index.html){.logo-icon .me-3 aria-label="HomePage"
alt="HomePage"}

![](data:image/svg+xml;base64,PHN2ZyBpZD0iTGF5ZXJfMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2aWV3Ym94PSIwIDAgMjUwIDI1MCI+PHBhdGggZD0ibTE0MyAzOS41Yy0xOCAwLTE4IDE4LTE4IDE4czAtMTgtMTgtMThIMjJjLTIuNzYuMC01IDIuMjQtNSA1djE0M2MwIDIuNzYgMi4yNCA1IDUgNWg3NmM3LjIuMCA4LjY0IDExLjUyIDguOTMgMTYuMTMuMDcgMS4wNS45NSAxLjg3IDIgMS44N2gzMi4xNGMxLjA2LjAgMS45NC0uODIgMi0xLjg3LjI5LTQuNjEgMS43My0xNi4xMyA4LjkzLTE2LjEzaDc2YzIuNzYuMCA1LTIuMjQgNS01VjQ0LjVjMC0yLjc2LTIuMjQtNS01LTVoLTg1ek0yMDYgMTYzYzAgMS4zOC0xLjEyIDIuNS0yLjUgMi41SDE0M2MtMTggMC0xOCAxOC0xOCAxOHMwLTE4LTE4LTE4SDQ2LjVjLTEuMzguMC0yLjUtMS4xMi0yLjUtMi41VjY5YzAtMS4zOCAxLjEyLTIuNSAyLjUtMi41SDk4YzcuMi4wIDguNjQgMTEuNTIgOC45MyAxNi4xMy4wNyAxLjA1Ljk1IDEuODcgMiAxLjg3aDMyLjE0YzEuMDYuMCAxLjk0LS44MiAyLTEuODcuMjktNC42MSAxLjczLTE2LjEzIDguOTMtMTYuMTNoNTEuNWMxLjM4LjAgMi41IDEuMTIgMi41IDIuNXY5NHoiIHN0eWxlPSJmaWxsOiMwNmYiIC8+PC9zdmc+){#Layer_1}

![](data:image/svg+xml;base64,PHN2ZyBpZD0iTGF5ZXJfMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2aWV3Ym94PSIwIDAgMjUwIDI1MCI+PHBhdGggZD0ibTE0MyAzOS41Yy0xOCAwLTE4IDE4LTE4IDE4czAtMTgtMTgtMThIMjJjLTIuNzYuMC01IDIuMjQtNSA1djE0M2MwIDIuNzYgMi4yNCA1IDUgNWg3NmM3LjIuMCA4LjY0IDExLjUyIDguOTMgMTYuMTMuMDcgMS4wNS45NSAxLjg3IDIgMS44N2gzMi4xNGMxLjA2LjAgMS45NC0uODIgMi0xLjg3LjI5LTQuNjEgMS43My0xNi4xMyA4LjkzLTE2LjEzaDc2YzIuNzYuMCA1LTIuMjQgNS01VjQ0LjVjMC0yLjc2LTIuMjQtNS01LTVoLTg1ek0yMDYgMTYzYzAgMS4zOC0xLjEyIDIuNS0yLjUgMi41SDE0M2MtMTggMC0xOCAxOC0xOCAxOHMwLTE4LTE4LTE4SDQ2LjVjLTEuMzguMC0yLjUtMS4xMi0yLjUtMi41VjY5YzAtMS4zOCAxLjEyLTIuNSAyLjUtMi41SDk4YzcuMi4wIDguNjQgMTEuNTIgOC45MyAxNi4xMy4wNyAxLjA1Ljk1IDEuODcgMiAxLjg3aDMyLjE0YzEuMDYuMCAxLjk0LS44MiAyLTEuODcuMjktNC42MSAxLjczLTE2LjEzIDguOTMtMTYuMTNoNTEuNWMxLjM4LjAgMi41IDEuMTIgMi41IDIuNXY5NHoiIHN0eWxlPSJmaWxsOiMwNmYiIC8+PC9zdmc+){#Layer_1}

[menu]{.material-icons .size-20 .menu-icon .align-middle}

[search]{.material-icons .size-20 .menu-icon .align-middle}
[Search]{.flexsearch-button-placeholder .ms-1 .me-2 .d-none .d-sm-block}

[[![](data:image/svg+xml;base64,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)]{.kbd
.flexsearch-button-cmd-key}[![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUiIGhlaWdodD0iMTUiPjxwYXRoIGQ9Ik01LjkyNiAxMi4yNzlINC40MUw5LjA3MyAyLjcyMUgxMC41OXoiIGZpbGw9ImN1cnJlbnRjb2xvciIgLz48L3N2Zz4=)]{.kbd
.flexsearch-button-key}]{.flexsearch-button-keys}

##### Star us on GitHub !¬†

[Star](https://github.com/mudler/LocalAI){.github-button
color-scheme="no-preference: light; light: light; dark: dark;"
icon="octicon-star" data-size="large" show-count="true"
aria-label="Star mudler/LocalAI on GitHub"}

-   [](https://github.com/mudler/LocalAI){alt="github"
    rel="noopener noreferrer" target="_blank"}

    ![](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld2JveD0iMCAwIDI0IDI0IiBmaWxsPSJub25lIiBzdHJva2U9ImN1cnJlbnRjb2xvciIgc3Ryb2tlLXdpZHRoPSIyIiBzdHJva2UtbGluZWNhcD0icm91bmQiIHN0cm9rZS1saW5lam9pbj0icm91bmQiPjx0aXRsZT5HaXRIdWI8L3RpdGxlPjxwYXRoIGQ9Ik05IDE5Yy01IDEuNS01LTIuNS03LTNtMTQgNnYtMy44N2EzLjM3IDMuMzcuMCAwMC0uOTQtMi42MWMzLjE0LS4zNSA2LjQ0LTEuNTQgNi40NC03QTUuNDQgNS40NC4wIDAwMjAgNC43NyA1LjA3IDUuMDcuMCAwMDE5LjkxIDFTMTguNzMuNjUgMTYgMi40OGExMy4zOCAxMy4zOC4wIDAwLTcgMEM2LjI3LjY1IDUuMDkgMSA1LjA5IDFBNS4wNyA1LjA3LjAgMDA1IDQuNzcgNS40NCA1LjQ0LjAgMDAzLjUgOC41NWMwIDUuNDIgMy4zIDYuNjEgNi40NCA3QTMuMzcgMy4zNy4wIDAwOSAxOC4xM1YyMiIgLz48L3N2Zz4=)
-   [](https://twitter.com/LocalAI_API){alt="twitter"
    rel="noopener noreferrer" target="_blank"}

    ![](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld2JveD0iMCAwIDI0IDI0Ij48dGl0bGU+VHdpdHRlciAvIFg8L3RpdGxlPjxwYXRoIGQ9Ik0uMDg4Ljc2OGw5LjI2NiAxMi4zOUwuMDI5IDIzLjIzMWgyLjFsOC4xNjMtOC44MTkgNi42IDguODE5aDcuMTQyTDE0LjI0MiAxMC4xNDUgMjIuOTIxLjc2OGgtMi4xTDEzLjMgOC44OTEgNy4yMjkuNzY4ek0zLjE3NCAyLjMxNEg2LjQ1NUwyMC45NDIgMjEuNjg1aC0zLjI4eiIgZmlsbD0iY3VycmVudGNvbG9yIiAvPjwvc3ZnPg==)
-   [](../../index.xml){alt="rss" rel="noopener noreferrer"
    target="_blank"}

    ![](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld2JveD0iMCAwIDI0IDI0IiBmaWxsPSJub25lIiBzdHJva2U9ImN1cnJlbnRjb2xvciIgc3Ryb2tlLXdpZHRoPSIyIiBzdHJva2UtbGluZWNhcD0icm91bmQiIHN0cm9rZS1saW5lam9pbj0icm91bmQiPjx0aXRsZT5SU1M8L3RpdGxlPjxwYXRoIGQ9Ik00IDExYTkgOSAwIDAxOSA5IiAvPjxwYXRoIGQ9Ik00IDRhMTYgMTYgMCAwMTE2IDE2IiAvPjxjaXJjbGUgY3g9IjUiIGN5PSIxOSIgcj0iMSI+PC9jaXJjbGU+PC9zdmc+)

[![](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMzAiIHdpZHRoPSIzMCIgdmlld2JveD0iMCAwIDQ4IDQ4IiBmaWxsPSJjdXJyZW50Y29sb3IiPjx0aXRsZT5FbmFibGUgZGFyayBtb2RlPC90aXRsZT48cGF0aCBkPSJNMjQgNDJxLTcuNS4wLTEyLjc1LTUuMjVUNiAyNHQ1LjI1LTEyLjc1VDI0IDZxLjQuMC44NS4wMjUuNDUuMDI1IDEuMTUuMDc1LTEuOCAxLjYtMi44IDMuOTV0LTEgNC45NXEwIDQuNSAzLjE1IDcuNjVRMjguNSAyNS44IDMzIDI1LjhxMi42LjAgNC45NS0uOTI1VDQxLjkgMjIuM3EuMDUuNi4wNzUuOTc1UTQyIDIzLjY1IDQyIDI0cTAgNy41LTUuMjUgMTIuNzVUMjQgNDJ6bTAtM3E1LjQ1LjAgOS41LTMuMzc1dDUuMDUtNy45MjVxLTEuMjUuNTUtMi42NzUuODI1UTM0LjQ1IDI4LjggMzMgMjguOHEtNS43NS4wLTkuNzc1LTQuMDI1VDE5LjIgMTVxMC0xLjIuMjUtMi41NzV0LjktMy4xMjVxLTQuOSAxLjM1LTguMTI1IDUuNDc1UTkgMTguOSA5IDI0cTAgNi4yNSA0LjM3NSAxMC42MjVUMjQgMzl6bS0uMi0xNC44NXoiIC8+PC9zdmc+)]{.toggle-dark}[![](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMzAiIHdpZHRoPSIzMCIgdmlld2JveD0iMCAwIDQ4IDQ4IiBmaWxsPSJjdXJyZW50Y29sb3IiPjx0aXRsZT5FbmFibGUgbGlnaHQgbW9kZTwvdGl0bGU+PHBhdGggZD0iTTI0IDMxcTIuOS4wIDQuOTUtMi4wNVQzMSAyNHQtMi4wNS00Ljk1VDI0IDE3dC00Ljk1IDIuMDVUMTcgMjR0Mi4wNSA0Ljk1VDI0IDMxem0wIDNxLTQuMTUuMC03LjA3NS0yLjkyNVQxNCAyNHQyLjkyNS03LjA3NVQyNCAxNHQ3LjA3NSAyLjkyNVQzNCAyNHQtMi45MjUgNy4wNzVUMjQgMzR6TTMuNSAyNS41cS0uNjUuMC0xLjA3NS0uNDI1UTIgMjQuNjUgMiAyNHQuNDI1LTEuMDc1UTIuODUgMjIuNSAzLjUgMjIuNWg1cS42NS4wIDEuMDc1LjQyNVExMCAyMy4zNSAxMCAyNHQtLjQyNSAxLjA3NVQ4LjUgMjUuNXptMzYgMHEtLjY1LjAtMS4wNzUtLjQyNVEzOCAyNC42NSAzOCAyNHQuNDI1LTEuMDc1VDM5LjUgMjIuNWg1cS42NS4wIDEuMDc1LjQyNVE0NiAyMy4zNSA0NiAyNHQtLjQyNSAxLjA3NS0xLjA3NS40MjV6TTI0IDEwcS0uNjUuMC0xLjA3NS0uNDI1UTIyLjUgOS4xNSAyMi41IDguNXYtNXEwLS42NS40MjUtMS4wNzVRMjMuMzUgMiAyNCAydDEuMDc1LjQyNVQyNS41IDMuNXY1cTAgLjY1LS40MjUgMS4wNzVRMjQuNjUgMTAgMjQgMTB6bTAgMzZxLS42NS4wLTEuMDc1LS40MjVUMjIuNSA0NC41di01cTAtLjY1LjQyNS0xLjA3NVEyMy4zNSAzOCAyNCAzOHQxLjA3NS40MjUuNDI1IDEuMDc1djVxMCAuNjUtLjQyNSAxLjA3NVEyNC42NSA0NiAyNCA0NnpNMTIgMTQuMWwtMi44NS0yLjhxLS40NS0uNDUtLjQyNS0xLjA3NS4wMjUtLjYyNS40MjUtMS4wNzUuNDUtLjQ1IDEuMDc1LS40NXQxLjA3NS40NUwxNC4xIDEycS40LjQ1LjQgMS4wNS4wLjYtLjQgMS0uNC40NS0xLjAyNS40NVQxMiAxNC4xem0yNC43IDI0Ljc1TDMzLjkgMzZxLS40LS40NS0uNC0xLjA3NXQuNDUtMS4wMjVxLjQtLjQ1IDEtLjQ1dDEuMDUuNDVsMi44NSAyLjhxLjQ1LjQ1LjQyNSAxLjA3NS0uMDI1LjYyNS0uNDI1IDEuMDc1LS40NS40NS0xLjA3NS40NXQtMS4wNzUtLjQ1ek0zMy45IDE0LjFxLS40NS0uNDUtLjQ1LTEuMDUuMC0uNi40NS0xLjA1bDIuOC0yLjg1cS40NS0uNDUgMS4wNzUtLjQyNS42MjUuMDI1IDEuMDc1LjQyNS40NS40NS40NSAxLjA3NXQtLjQ1IDEuMDc1TDM2IDE0LjFxLS40LjQtMS4wMjUuNHQtMS4wNzUtLjR6TTkuMTUgMzguODVxLS40NS0uNDUtLjQ1LTEuMDc1dC40NS0xLjA3NUwxMiAzMy45cS40NS0uNDUgMS4wNS0uNDUuNi4wIDEuMDUuNDUuNDUuNDUuNDUgMS4wNS4wLjYtLjQ1IDEuMDVsLTIuOCAyLjg1cS0uNDUuNDUtMS4wNzUuNDI1LS42MjUtLjAyNS0xLjA3NS0uNDI1ek0yNCAyNHoiIC8+PC9zdmc+)]{.toggle-light}

[![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUiIGhlaWdodD0iMTUiIGFyaWEtbGFiZWw9IkFycm93IGRvd24iIHJvbGU9ImltZyI+PGcgZmlsbD0ibm9uZSIgc3Ryb2tlPSJjdXJyZW50Y29sb3IiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCIgc3Ryb2tlLWxpbmVqb2luPSJyb3VuZCIgc3Ryb2tlLXdpZHRoPSIxLjIiPjxwYXRoIGQ9Ik03LjUgMy41djhtMy0zLTMgMy0zLTMiIC8+PC9nPjwvc3ZnPg==)]{.kbd
.flexsearch-button-cmd-key}[![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUiIGhlaWdodD0iMTUiIGFyaWEtbGFiZWw9IkFycm93IHVwIiByb2xlPSJpbWciPjxnIGZpbGw9Im5vbmUiIHN0cm9rZT0iY3VycmVudGNvbG9yIiBzdHJva2UtbGluZWNhcD0icm91bmQiIHN0cm9rZS1saW5lam9pbj0icm91bmQiIHN0cm9rZS13aWR0aD0iMS4yIj48cGF0aCBkPSJNNy41IDExLjV2LThtMyAzLTMtMy0zIDMiIC8+PC9nPjwvc3ZnPg==)]{.kbd
.flexsearch-button-cmd-key}[to navigate]{.flexsearch-key-label}

[![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUiIGhlaWdodD0iMTUiIGFyaWEtbGFiZWw9IkVudGVyIGtleSIgcm9sZT0iaW1nIj48ZyBmaWxsPSJub25lIiBzdHJva2U9ImN1cnJlbnRjb2xvciIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIiBzdHJva2UtbGluZWpvaW49InJvdW5kIiBzdHJva2Utd2lkdGg9IjEuMiI+PHBhdGggZD0iTTEyIDMuNTMwODh2M2MwIDEtMSAyLTIgMkg0bTMgMy0zLTMgMy0zIiAvPjwvZz48L3N2Zz4=)]{.kbd
.flexsearch-button-cmd-key}[to select]{.flexsearch-key-label}

[![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUiIGhlaWdodD0iMTUiIGFyaWEtbGFiZWw9IkVzY2FwZSBrZXkiIHJvbGU9ImltZyI+PGcgZmlsbD0ibm9uZSIgc3Ryb2tlPSJjdXJyZW50Y29sb3IiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCIgc3Ryb2tlLWxpbmVqb2luPSJyb3VuZCIgc3Ryb2tlLXdpZHRoPSIxLjIiPjxwYXRoIGQ9Ik0xMy42MTY3IDguOTM2Yy0uMTA2NS4zNTgzLS42ODgzLjk2Mi0xLjQ4NzUuOTYyLS43OTkzLjAtMS42NTMtLjkxNjUtMS42NTMtMi4xMjU4di0uNTY3OGMwLTEuMjU0OC43ODk2LTIuMTAxNiAxLjY1My0yLjEwMTZzMS4zNjAxLjQ3NzggMS40ODc1IDEuMDcyNE05IDZjLS4xMzUyLS40NzM1LS43NTA2LS45MjE5LTEuNDYtLjg5NzItLjcwOTIuMDI0Ni0xLjM0NC41Ny0xLjM0NCAxLjIxNjZzLjQxOTguODgxMiAxLjM0NDUuOTgwNUM4LjQ2NSA3LjM5OTIgOC45NjggNy45MzM3IDkgOC41cy0uNDU0IDEuMzk4LTEuNDU5NSAxLjM5OEM2LjY1OTMgOS44OTggNiA5IDUuOTYzIDguNDg1MW0tMS40NzQ4LjUzNjhjLS4yNjM1LjU5NDEtLjgwOTkuODc2LTEuNTQ0My44NzZzLTEuNzA3My0uNjI0OC0xLjcwNzMtMi4yMDR2LS40NjAzYzAtMS4wNDE2LjcyMS0yLjEzMSAxLjcwNzMtMi4xMzEuOTg2NC4wIDEuNjQyNSAxLjAzMSAxLjU0NDMgMi4yNDkyaC0yLjk1NiIgLz48L2c+PC9zdmc+)]{.kbd
.flexsearch-button-cmd-key}[to close]{.flexsearch-key-label}

cancel


-   [*Home*](../../docs){itemprop="item"}
-   [[Getting
    started]{itemprop="name"}](https://localai.io/docs/getting-started/){itemprop="item"}
-   [Build LocalAI from source]{itemprop="name"}

On this page

-   -   -   [Build](index.html#build)
        -   [Example: Build on mac](index.html#example-build-on-mac)
        -   [Build with Text to audio
            support](index.html#build-with-text-to-audio-support)
        -   [Acceleration](index.html#acceleration)
        -   [Windows compatibility](index.html#windows-compatibility)
        -   [Examples](index.html#examples)

Table of Contents

-   -   -   [Build](index.html#build)
        -   [Example: Build on mac](index.html#example-build-on-mac)
        -   [Build with Text to audio
            support](index.html#build-with-text-to-audio-support)
        -   [Acceleration](index.html#acceleration)
        -   [Windows compatibility](index.html#windows-compatibility)
        -   [Examples](index.html#examples)

*article*

# Build LocalAI from source {#build-localai-from-source .content-title .mb-0}

### Build [*link*](index.html#build){.anchor aria-hidden="true"} {#build}

LocalAI can be built as a container image or as a single, portable
binary. Note that the some model architectures might require Python
libraries, which are not included in the binary. The binary contains
only the core backends written in Go and C++.

LocalAI's extensible architecture allows you to add your own backends,
which can be written in any language, and as such the container images
contains also the Python dependencies to run all the available backends
(for example, in order to run backends like **Diffusers** that allows to
generate images and videos from text).

In some cases you might want to re-build LocalAI from source (for
instance to leverage Apple Silicon acceleration), or to build a custom
container image with your own backends. This section contains
instructions on how to build LocalAI from source.

#### Build LocalAI locally [*link*](index.html#build-localai-locally){.anchor aria-hidden="true"} {#build-localai-locally}

##### Requirements [*link*](index.html#requirements){.anchor aria-hidden="true"} {#requirements}

In order to build LocalAI locally, you need the following requirements:

-   Golang \>= 1.21
-   Cmake/make
-   GCC
-   GRPC

To install the dependencies follow the instructions below:

[Apple]{#deafbcTab .nav-link .active bs-toggle="tab" bs-target="#deafbc"
type="button" role="tab" aria-controls="deafbc" aria-selected="true"}
[Debian]{#fbcaedTab .nav-link bs-toggle="tab" bs-target="#fbcaed"
type="button" role="tab" aria-controls="fbcaed" aria-selected="true"}
[From source]{#bdeafcTab .nav-link bs-toggle="tab" bs-target="#bdeafc"
type="button" role="tab" aria-controls="bdeafc" aria-selected="true"}

Install `xcode` from the App Store

``` {#3a8dccd .language-bash}
  brew install abseil cmake go grpc protobuf protoc-gen-go protoc-gen-go-grpc python wget
  
```

After installing the above dependencies, you need to install
grpcio-tools from PyPI. You could do this via a pip --user install or a
virtualenv.

``` {#2e12a21 .language-bash}
  pip install --user grpcio-tools
  
```

``` {#602ee2a .language-bash}
  apt install cmake golang libgrpc-dev make protobuf-compiler-grpc python3-grpc-tools
  
```

After you have golang installed and working, you can install the
required binaries for compiling the golang protobuf components via the
following commands

``` {#f3d1a0e .language-bash}
  go install google.golang.org/protobuf/cmd/[email¬†protected]
go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@1958fcbe2ca8bd93af633f11e97d44e567e945af
  
```

Specify `BUILD_GRPC_FOR_BACKEND_LLAMA=true` to build automatically the
gRPC dependencies

``` {#cfb95fe .language-bash}
  make ... BUILD_GRPC_FOR_BACKEND_LLAMA=true build
  
```

##### Build [*link*](index.html#build-1){.anchor aria-hidden="true"} {#build-1}

To build LocalAI with `make`:

``` {#657bc1c .language-}
  git clone https://github.com/go-skynet/LocalAI
cd LocalAI
make build
  
```

This should produce the binary `local-ai`

Here is the list of the variables available that can be used to
customize the build:

  Variable           Default                 Description
  ------------------ ----------------------- --------------------------------------------------------------------------------------------------
  `BUILD_TYPE`       None                    Build type. Available: `cublas`, `openblas`, `clblas`, `metal`,`hipblas`, `sycl_f16`, `sycl_f32`
  `GO_TAGS`          `tts stablediffusion`   Go tags. Available: `stablediffusion`, `tts`
  `CLBLAST_DIR`                              Specify a CLBlast directory
  `CUDA_LIBPATH`                             Specify a CUDA library path
  `BUILD_API_ONLY`   false                   Set to true to build only the API (no backends will be built)

[notifications]{.material-icons .size-20 .me-2}

#### CPU flagset compatibility [*link*](index.html#cpu-flagset-compatibility){.anchor aria-hidden="true"} {#cpu-flagset-compatibility}

LocalAI uses different backends based on ggml and llama.cpp to run
models. If your CPU doesn't support common instruction sets, you can
disable them during build:

``` {#06bde2f .language-}
  CMAKE_ARGS="-DGGML_F16C=OFF -DGGML_AVX512=OFF -DGGML_AVX2=OFF -DGGML_AVX=OFF -DGGML_FMA=OFF" make build
  
```

To have effect on the container image, you need to set `REBUILD=true`:

``` {#257659b .language-}
  docker run  quay.io/go-skynet/localai
docker run --rm -ti -p 8080:8080 -e DEBUG=true -e MODELS_PATH=/models -e THREADS=1 -e REBUILD=true -e CMAKE_ARGS="-DGGML_F16C=OFF -DGGML_AVX512=OFF -DGGML_AVX2=OFF -DGGML_AVX=OFF -DGGML_FMA=OFF" -v $PWD/models:/models quay.io/go-skynet/local-ai:latest
  
```

#### Container image [*link*](index.html#container-image){.anchor aria-hidden="true"} {#container-image}

Requirements:

-   Docker or podman, or a container engine

In order to build the `LocalAI` container image locally you can use
`docker`, for example:

``` {#c2aedd3 .language-}
  # build the image
docker build -t localai .
docker run localai
  
```

There are some build arguments that can be used to customize the build:

  Variable       Default    Description
  -------------- ---------- -----------------------------------------
  `IMAGE_TYPE`   `extras`   Build type. Available: `core`, `extras`

### Example: Build on mac [*link*](index.html#example-build-on-mac){.anchor aria-hidden="true"} {#example-build-on-mac}

Building on Mac (M1, M2 or M3) works, but you may need to install some
prerequisites using `brew`.

The below has been tested by one mac user and found to work. Note that
this doesn't use Docker to run the server:

Install `xcode` from the Apps Store (needed for metalkit)

``` {#e891e8c .language-}
  # install build dependencies
brew install abseil cmake go grpc protobuf wget protoc-gen-go protoc-gen-go-grpc

# clone the repo
git clone https://github.com/go-skynet/LocalAI.git

cd LocalAI

# build the binary
make build

# Download phi-2 to models/
wget https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q2_K.gguf -O models/phi-2.Q2_K

# Use a template from the examples
cp -rf prompt-templates/ggml-gpt4all-j.tmpl models/phi-2.Q2_K.tmpl

# Run LocalAI
./local-ai --models-path=./models/ --debug=true

# Now API is accessible at localhost:8080
curl http://localhost:8080/v1/models

curl http://localhost:8080/v1/chat/completions -H "Content-Type: application/json" -d '{
     "model": "phi-2.Q2_K",
     "messages": [{"role": "user", "content": "How are you?"}],
     "temperature": 0.9 
   }'
  
```

#### Troubleshooting mac [*link*](index.html#troubleshooting-mac){.anchor aria-hidden="true"} {#troubleshooting-mac}

-   If you encounter errors regarding a missing utility metal, install
    `Xcode` from the App Store.

-   After the installation of Xcode, if you receive a xcrun error
    `'xcrun: error: unable to find utility "metal", not a developer tool or in PATH'`.
    You might have installed the Xcode command line tools before
    installing Xcode, the former one is pointing to an incomplete SDK.

``` {#0b0ccbf .language-}
  # print /Library/Developer/CommandLineTools, if command line tools were installed in advance
xcode-select --print-path

# point to a complete SDK
sudo xcode-select --switch /Applications/Xcode.app/Contents/Developer
  
```

-   If completions are slow, ensure that `gpu-layers` in your model yaml
    matches the number of layers from the model in use (or simply use a
    high number such as 256).

-   If you a get a compile error:
    `error: only virtual member functions can be marked 'final'`,
    reinstall all the necessary brew packages, clean the build, and try
    again.

``` {#c9151e9 .language-}
  # reinstall build dependencies
brew reinstall abseil cmake go grpc protobuf wget

make clean

make build
  
```

**Requirements**: OpenCV, Gomp

Image generation requires `GO_TAGS=stablediffusion` to be set during
build:

``` {#dee48f7 .language-}
  make GO_TAGS=stablediffusion build
  
```

### Build with Text to audio support [*link*](index.html#build-with-text-to-audio-support){.anchor aria-hidden="true"} {#build-with-text-to-audio-support}

**Requirements**: piper-phonemize

Text to audio support is experimental and requires `GO_TAGS=tts` to be
set during build:

``` {#02569bc .language-}
  make GO_TAGS=tts build
  
```

### Acceleration [*link*](index.html#acceleration){.anchor aria-hidden="true"} {#acceleration}

#### OpenBLAS [*link*](index.html#openblas){.anchor aria-hidden="true"} {#openblas}

Software acceleration.

Requirements: OpenBLAS

``` {#db75611 .language-}
  make BUILD_TYPE=openblas build
  
```

#### CuBLAS [*link*](index.html#cublas){.anchor aria-hidden="true"} {#cublas}

Nvidia Acceleration.

Requirement: Nvidia CUDA toolkit

Note: CuBLAS support is experimental, and has not been tested on real
HW. please report any issues you find!

``` {#5c52c9a .language-}
  make BUILD_TYPE=cublas build
  
```

More informations available in the upstream PR:
[https://github.com/ggerganov/llama.cpp/pull/1412![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdib3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48cGF0aCBmaWxsPSJjdXJyZW50Y29sb3IiIGQ9Ik0xNCA1Yy0uNTUyLjAtMS0uNDQ4LTEtMXMuNDQ4LTEgMS0xaDZjLjU1Mi4wIDEgLjQ0OCAxIDF2NmMwIC41NTItLjQ0OCAxLTEgMXMtMS0uNDQ4LTEtMVY2LjQxNGwtNy4yOTMgNy4yOTNjLS4zOTEuMzktMS4wMjQuMzktMS40MTQuMC0uMzkxLS4zOTEtLjM5MS0xLjAyNC4wLTEuNDE0TDE3LjU4NiA1SDE0ek01IDdjLS41NTIuMC0xIC40NDgtMSAxdjExYzAgLjU1Mi40NDggMSAxIDFoMTFjLjU1Mi4wIDEtLjQ0OCAxLTF2LTQuNTYzYzAtLjU1Mi40NDgtMSAxLTFzMSAuNDQ4IDEgMVYxOWMwIDEuNjU3LTEuMzQzIDMtMyAzSDVjLTEuNjU3LjAtMy0xLjM0My0zLTNWOGMwLTEuNjU3IDEuMzQzLTMgMy0zaDQuNTYzYy41NTIuMCAxIC40NDggMSAxcy0uNDQ4IDEtMSAxSDV6IiAvPjwvc3ZnPg==)](https://github.com/ggerganov/llama.cpp/pull/1412){rel="external"
target="_blank"}

#### Hipblas (AMD GPU with ROCm on Arch Linux) [*link*](index.html#hipblas-amd-gpu-with-rocm-on-arch-linux){.anchor aria-hidden="true"} {#hipblas-amd-gpu-with-rocm-on-arch-linux}

Packages:

``` {#5666131 .language-}
  pacman -S base-devel git rocm-hip-sdk rocm-opencl-sdk opencv clblast grpc
  
```

Library links:

``` {#3330b64 .language-}
  export CGO_CFLAGS="-I/usr/include/opencv4"
export CGO_CXXFLAGS="-I/usr/include/opencv4"
export CGO_LDFLAGS="-L/opt/rocm/hip/lib -lamdhip64 -L/opt/rocm/lib -lOpenCL -L/usr/lib -lclblast -lrocblas -lhipblas -lrocrand -lomp -O3 --rtlib=compiler-rt -unwindlib=libgcc -lhipblas -lrocblas --hip-link"
  
```

Build:

``` {#d9e4347 .language-}
  make BUILD_TYPE=hipblas GPU_TARGETS=gfx1030
  
```

#### ClBLAS [*link*](index.html#clblas){.anchor aria-hidden="true"} {#clblas}

AMD/Intel GPU acceleration.

Requirement: OpenCL, CLBlast

``` {#2d82cd1 .language-}
  make BUILD_TYPE=clblas build
  
```

To specify a clblast dir set: `CLBLAST_DIR`

#### Intel GPU acceleration [*link*](index.html#intel-gpu-acceleration){.anchor aria-hidden="true"} {#intel-gpu-acceleration}

Intel GPU acceleration is supported via SYCL.

Requirements: [Intel oneAPI Base
Toolkit![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdib3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48cGF0aCBmaWxsPSJjdXJyZW50Y29sb3IiIGQ9Ik0xNCA1Yy0uNTUyLjAtMS0uNDQ4LTEtMXMuNDQ4LTEgMS0xaDZjLjU1Mi4wIDEgLjQ0OCAxIDF2NmMwIC41NTItLjQ0OCAxLTEgMXMtMS0uNDQ4LTEtMVY2LjQxNGwtNy4yOTMgNy4yOTNjLS4zOTEuMzktMS4wMjQuMzktMS40MTQuMC0uMzkxLS4zOTEtLjM5MS0xLjAyNC4wLTEuNDE0TDE3LjU4NiA1SDE0ek01IDdjLS41NTIuMC0xIC40NDgtMSAxdjExYzAgLjU1Mi40NDggMSAxIDFoMTFjLjU1Mi4wIDEtLjQ0OCAxLTF2LTQuNTYzYzAtLjU1Mi40NDgtMSAxLTFzMSAuNDQ4IDEgMVYxOWMwIDEuNjU3LTEuMzQzIDMtMyAzSDVjLTEuNjU3LjAtMy0xLjM0My0zLTNWOGMwLTEuNjU3IDEuMzQzLTMgMy0zaDQuNTYzYy41NTIuMCAxIC40NDggMSAxcy0uNDQ4IDEtMSAxSDV6IiAvPjwvc3ZnPg==)](https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit-download.html){rel="external"
target="_blank"} (see also [llama.cpp setup installations
instructions![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdib3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48cGF0aCBmaWxsPSJjdXJyZW50Y29sb3IiIGQ9Ik0xNCA1Yy0uNTUyLjAtMS0uNDQ4LTEtMXMuNDQ4LTEgMS0xaDZjLjU1Mi4wIDEgLjQ0OCAxIDF2NmMwIC41NTItLjQ0OCAxLTEgMXMtMS0uNDQ4LTEtMVY2LjQxNGwtNy4yOTMgNy4yOTNjLS4zOTEuMzktMS4wMjQuMzktMS40MTQuMC0uMzkxLS4zOTEtLjM5MS0xLjAyNC4wLTEuNDE0TDE3LjU4NiA1SDE0ek01IDdjLS41NTIuMC0xIC40NDgtMSAxdjExYzAgLjU1Mi40NDggMSAxIDFoMTFjLjU1Mi4wIDEtLjQ0OCAxLTF2LTQuNTYzYzAtLjU1Mi40NDgtMSAxLTFzMSAuNDQ4IDEgMVYxOWMwIDEuNjU3LTEuMzQzIDMtMyAzSDVjLTEuNjU3LjAtMy0xLjM0My0zLTNWOGMwLTEuNjU3IDEuMzQzLTMgMy0zaDQuNTYzYy41NTIuMCAxIC40NDggMSAxcy0uNDQ4IDEtMSAxSDV6IiAvPjwvc3ZnPg==)](https://github.com/ggerganov/llama.cpp/blob/d71ac90985854b0905e1abba778e407e17f9f887/README-sycl.md?plain=1#L56){rel="external"
target="_blank"})

``` {#3034869 .language-}
  make BUILD_TYPE=sycl_f16 build # for float16
make BUILD_TYPE=sycl_f32 build # for float32
  
```

#### Metal (Apple Silicon) [*link*](index.html#metal-apple-silicon){.anchor aria-hidden="true"} {#metal-apple-silicon}

``` {#3d68fbf .language-}
  make build

# correct build type is automatically used on mac (BUILD_TYPE=metal)
# Set `gpu_layers: 256` (or equal to the number of model layers) to your YAML model config file and `f16: true`
  
```

### Windows compatibility [*link*](index.html#windows-compatibility){.anchor aria-hidden="true"} {#windows-compatibility}

Make sure to give enough resources to the running container. See
[https://github.com/go-skynet/LocalAI/issues/2![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdib3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48cGF0aCBmaWxsPSJjdXJyZW50Y29sb3IiIGQ9Ik0xNCA1Yy0uNTUyLjAtMS0uNDQ4LTEtMXMuNDQ4LTEgMS0xaDZjLjU1Mi4wIDEgLjQ0OCAxIDF2NmMwIC41NTItLjQ0OCAxLTEgMXMtMS0uNDQ4LTEtMVY2LjQxNGwtNy4yOTMgNy4yOTNjLS4zOTEuMzktMS4wMjQuMzktMS40MTQuMC0uMzkxLS4zOTEtLjM5MS0xLjAyNC4wLTEuNDE0TDE3LjU4NiA1SDE0ek01IDdjLS41NTIuMC0xIC40NDgtMSAxdjExYzAgLjU1Mi40NDggMSAxIDFoMTFjLjU1Mi4wIDEtLjQ0OCAxLTF2LTQuNTYzYzAtLjU1Mi40NDgtMSAxLTFzMSAuNDQ4IDEgMVYxOWMwIDEuNjU3LTEuMzQzIDMtMyAzSDVjLTEuNjU3LjAtMy0xLjM0My0zLTNWOGMwLTEuNjU3IDEuMzQzLTMgMy0zaDQuNTYzYy41NTIuMCAxIC40NDggMSAxcy0uNDQ4IDEtMSAxSDV6IiAvPjwvc3ZnPg==)](https://github.com/go-skynet/LocalAI/issues/2){rel="external"
target="_blank"}

### Examples [*link*](index.html#examples){.anchor aria-hidden="true"} {#examples}

More advanced build options are available, for instance to build only a
single backend.

#### Build only a single backend [*link*](index.html#build-only-a-single-backend){.anchor aria-hidden="true"} {#build-only-a-single-backend}

You can control the backends that are built by setting the
`GRPC_BACKENDS` environment variable. For instance, to build only the
`llama-cpp` backend only:

``` {#1eb127b .language-bash}
  make GRPC_BACKENDS=backend-assets/grpc/llama-cpp build
  
```

By default, all the backends are built.

#### Specific llama.cpp version [*link*](index.html#specific-llamacpp-version){.anchor aria-hidden="true"} {#specific-llamacpp-version}

To build with a specific version of llama.cpp, set `CPPLLAMA_VERSION` to
the tag or wanted sha:

``` {#e5523f9 .language-}
  CPPLLAMA_VERSION=<sha> make build
  
```

[[![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjAiIGhlaWdodD0iMjAiIHZpZXdib3g9IjAgMCAzMiAzMiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiBmaWxsPSJjdXJyZW50Y29sb3IiPjxwYXRoIGQ9Ik0xNiAuMzk2Yy04LjgzOS4wLTE2IDcuMTY3LTE2IDE2IDAgNy4wNzMgNC41ODQgMTMuMDY4IDEwLjkzNyAxNS4xODMuODAzLjE1MSAxLjA5My0uMzQ0IDEuMDkzLS43NzIuMC0uMzgtLjAwOS0xLjM4NS0uMDE1LTIuNzE5LTQuNDUzLjk2NC01LjM5MS0yLjE1MS01LjM5MS0yLjE1MS0uNzI5LTEuODQ0LTEuNzgxLTIuMzM5LTEuNzgxLTIuMzM5LTEuNDQ4LS45ODkuMTE1LS45NjguMTE1LS45NjggMS42MDQuMTA5IDIuNDQ4IDEuNjQ1IDIuNDQ4IDEuNjQ1IDEuNDI3IDIuNDQ4IDMuNzQ0IDEuNzQgNC42NjEgMS4zMjguMTQtMS4wMzEuNTU3LTEuNzQgMS4wMTEtMi4xMzUtMy41NTItLjQwMS03LjI4Ny0xLjc3Ni03LjI4Ny03LjkwNy4wLTEuNzUxLjYyLTMuMTc3IDEuNjQ1LTQuMjk3LS4xNzctLjQwMS0uNzE5LTIuMDMxLjE0MS00LjIzNS4wLjAgMS4zMzktLjQyNyA0LjQgMS42NDEgMS4yODEtLjM1NSAyLjY0MS0uNTMyIDQtLjU0MSAxLjM2LjAwOSAyLjcxOS4xODcgNCAuNTQxIDMuMDQzLTIuMDY4IDQuMzgxLTEuNjQxIDQuMzgxLTEuNjQxLjg1OSAyLjIwNC4zMTcgMy44MzMuMTYxIDQuMjM1IDEuMDE1IDEuMTIgMS42MzUgMi41NDcgMS42MzUgNC4yOTcuMCA2LjE0NS0zLjc0IDcuNS03LjI5NiA3Ljg5MS41NTYuNDc5IDEuMDc3IDEuNDY0IDEuMDc3IDIuOTU5LjAgMi4xNC0uMDIgMy44NjQtLjAyIDQuMzg1LjAuNDE2LjI4LjkxNiAxLjEwNC43NTUgNi40LTIuMDkzIDEwLjk3OS04LjA5MyAxMC45NzktMTUuMTU2LjAtOC44MzMtNy4xNjEtMTYtMTYtMTZ6IiAvPjwvc3ZnPg==)]{.me-1
.align-text-bottom}Edit this
page](https://github.com/mudler/LocalAI/blob/master/docs/content/docs/getting-started/build.md){alt="Build LocalAI from source"
rel="noopener noreferrer" target="_blank"}

Last updated [18 Jan 2025, 18:35 +0100 ]{#relativetime
authdate="2025-01-18T18:35:30+0100" title="18 Jan 2025, 18:35 +0100"}.
[history]{.material-icons .size-20 .align-text-bottom .opacity-75}

<div>

------------------------------------------------------------------------

[](https://localai.io/docs/getting-started/customize-model/)

*navigate_before* Customizing the Model

[](../container/index.html){.ms-auto}

Run with container images *navigate_next*

</div>

¬© 2023-2025 [Ettore Di Giacinto](https://mudler.pm){target="_blank"}

![](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiPjxwYXRoIGQ9Ik0xMiAxMC4yMjRsLTYuMyA2LjMtMS4zOC0xLjM3MkwxMiA3LjQ3Mmw3LjY4IDcuNjgtMS4zOCAxLjM3NnoiIHN0eWxlPSJmaWxsOiNmZmYiIC8+PC9zdmc+)
